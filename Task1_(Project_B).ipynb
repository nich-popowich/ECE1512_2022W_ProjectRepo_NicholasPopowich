{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task1 (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nich-popowich/ECE1512_2022W_ProjectRepo_NicholasPopowich/blob/main/Task1_(Project_B).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project B: Knowledge Distillation for Building Lightweight Deep Learning Models in Visual Classification Tasks"
      ],
      "metadata": {
        "id": "6WYMfvCNPwpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from typing import Union\n",
        "\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "builder = tfds.builder('mnist')\n",
        "BATCH_SIZE = 256\n",
        "NUM_EPOCHS = 12\n",
        "NUM_CLASSES = 10  # 10 total classes."
      ],
      "metadata": {
        "id": "vA8ppgB2P0aJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "#from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "6gnTDdemHLV0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading"
      ],
      "metadata": {
        "id": "H2EFLQROP2R7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and test splits.\n",
        "def preprocess(x):\n",
        "  image = tf.image.convert_image_dtype(x['image'], tf.float32)\n",
        "  class_labels = tf.one_hot(x['label'], builder.info.features['label'].num_classes)\n",
        "  return image, class_labels\n",
        "\n",
        "\n",
        "mnist_train = tfds.load('mnist', split='train', shuffle_files=False).cache()\n",
        "mnist_train = mnist_train.map(preprocess)\n",
        "mnist_train = mnist_train.shuffle(builder.info.splits['train'].num_examples)\n",
        "mnist_train = mnist_train.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "mnist_test = tfds.load('mnist', split='test').cache()\n",
        "mnist_test = mnist_test.map(preprocess).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "ynByMG_UP4A4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yV3LZSMfTtn",
        "outputId": "bd78417c-49c2-4f1e-e8ff-3c7786841553"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(256, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model creation"
      ],
      "metadata": {
        "id": "kAZwfvW5P63q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Build CNN teacher.\n",
        "#cnn_model = tf.keras.Sequential()\n",
        "\n",
        "# your code start from here for stpe 2\n",
        "teacher = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\"),\n",
        "        #layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        #layers.Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dropout(0.5),\n",
        "        #layers.Dense(10),\n",
        "        #layers.Dense(10, activation=\"softmax\")\n",
        "        layers.Dense(10)\n",
        "    ],\n",
        "    name=\"teacher\",\n",
        ")\n",
        "\n",
        "\n",
        "# Build fully connected student.\n",
        "#fc_model = tf.keras.Sequential()\n",
        "\n",
        "\n",
        "# your code start from here for step 2\n",
        "\n",
        "student = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(784, activation=\"relu\"),\n",
        "        layers.Dense(784, activation=\"relu\"),\n",
        "        #layers.Dense(10),\n",
        "        #layers.Dense(10, activation=\"softmax\")\n",
        "        layers.Dense(10)\n",
        "        # model.add(Activation('relu'))\n",
        "    ],\n",
        "    name=\"student\",\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zINgDkA7P7BP"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Xr_zY1WwCqpj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NLovqeysCqua"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher.fit(mnist_train, epochs=5)\n"
      ],
      "metadata": {
        "id": "zqdH3hz_Dm52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HnQNSu3P3Pb",
        "outputId": "4fd6da63-e8bf-4b38-d348-35c89a691b42"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"student\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_5 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 784)               615440    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 784)               615440    \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,238,730\n",
            "Trainable params: 1,238,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT4RNtGkCvDY",
        "outputId": "490a9d94-b508-4e12-e82e-dcda461edab9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"teacher\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " re_lu_4 (ReLU)              (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 28, 28, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " re_lu_5 (ReLU)              (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               1605760   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,625,866\n",
            "Trainable params: 1,625,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFfPuzb5J0Vu",
        "outputId": "006d558f-ab54-4116-8bb1-2e748147f4f6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(256, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the teacher model\n",
        "teacher.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "N3bzIjUUt94h"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher.fit(mnist_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ppTDqa_uA0o",
        "outputId": "4bc5be2b-d703-4b4e-b2b5-b3caebd326ff"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "234/234 [==============================] - 212s 896ms/step - loss: 1.7718 - accuracy: 0.5536\n",
            "Epoch 2/5\n",
            "234/234 [==============================] - 204s 863ms/step - loss: 1.0945 - accuracy: 0.7035\n",
            "Epoch 3/5\n",
            "234/234 [==============================] - 204s 865ms/step - loss: 0.7971 - accuracy: 0.7665\n",
            "Epoch 4/5\n",
            "234/234 [==============================] - 205s 868ms/step - loss: 0.6513 - accuracy: 0.8063\n",
            "Epoch 5/5\n",
            "234/234 [==============================] - 204s 862ms/step - loss: 0.5698 - accuracy: 0.8288\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f41080d5050>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher2 = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\"),\n",
        "        #layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        #layers.Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dropout(0.5),\n",
        "        #layers.Dense(10),\n",
        "        #layers.Dense(10, activation=\"softmax\")\n",
        "        layers.Dense(10)\n",
        "    ],\n",
        "    name=\"teacher2\",\n",
        ")"
      ],
      "metadata": {
        "id": "CfKu_WcK4SY0"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_example, =mnist_train.take(1)\n",
        "image, label = mnist_example\n"
      ],
      "metadata": {
        "id": "6aScN7bZ5pP6"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teacher loss function"
      ],
      "metadata": {
        "id": "8JWGucyrQGav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def compute_teacher_loss(images, labels):\n",
        "  \"\"\"Compute class knowledge distillation teacher loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  class_logits = teacher2(images, training=True)\n",
        "\n",
        "  # Compute cross-entropy loss for classes.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "  cross_entropy_loss_value =tf.keras.losses.categorical_crossentropy(labels, class_logits, from_logits=True)\n",
        "\n",
        "\n",
        "  return cross_entropy_loss_value"
      ],
      "metadata": {
        "id": "DhzBP6ZLQJ57"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_wo_hd_loss=compute_teacher_loss(image,label)"
      ],
      "metadata": {
        "id": "YIGHpYLc6r1j"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_wo_hd_loss"
      ],
      "metadata": {
        "id": "ZKmqlOcc6t_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loass function and optimizer\n",
        "# loss_func = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5) # Low since we are fine-tuning\n"
      ],
      "metadata": {
        "id": "OQx9quoK1NM5"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# teacher.compile(loss=compute_teacher_loss(), optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "t4JO_RGI0920"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student loss function"
      ],
      "metadata": {
        "id": "JS8xkuH0QbOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Hyperparameters for distillation (need to be tuned).\n",
        "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE = 4. #temperature hyperparameter\n",
        "\n",
        "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
        "                      temperature: Union[float, tf.Tensor]):\n",
        "  \"\"\"Compute distillation loss.\n",
        "\n",
        "  This function computes cross entropy between softened logits and softened\n",
        "  targets. The resulting loss is scaled by the squared temperature so that\n",
        "  the gradient magnitude remains approximately constant as the temperature is\n",
        "  changed. For reference, see Hinton et al., 2014, \"Distilling the knowledge in\n",
        "  a neural network.\"\n",
        "\n",
        "  Args:\n",
        "    teacher_logits: A Tensor of logits provided by the teacher.\n",
        "    student_logits: A Tensor of logits provided by the student, of the same\n",
        "      shape as `teacher_logits`.\n",
        "    temperature: Temperature to use for distillation.\n",
        "\n",
        "  Returns:\n",
        "    A scalar Tensor containing the distillation loss.\n",
        "  \"\"\"\n",
        " # your code start from here for step 3\n",
        "  soft_targets = teacher_logits / temperature\n",
        "\n",
        "  return tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(\n",
        "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
        "\n",
        "def compute_student_loss(images, labels):\n",
        "  \"\"\"Compute class knowledge distillation student loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  student_class_logits = student(images, training=True)\n",
        "\n",
        "  # Compute class distillation loss between student class logits and\n",
        "  # softened teacher class targets probabilities.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  teacher_class_logits = teacher(images, training=False)\n",
        "  distillation_loss_value =distillation_loss(teacher_class_logits,student_class_logits,DISTILLATION_TEMPERATURE)\n",
        "\n",
        "  # Compute cross-entropy loss with hard targets.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  cross_entropy_loss_value = tf.keras.losses.categorical_crossentropy(labels, student_class_logits, from_logits=True)\n",
        "  \n",
        "  total_loss =ALPHA*cross_entropy_loss_value + (1-ALPHA)*distillation_loss_value\n",
        "\n",
        "  return total_loss"
      ],
      "metadata": {
        "id": "lDKia4gPQMIr"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and evaluation"
      ],
      "metadata": {
        "id": "RJ1uyvurQ3w4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def compute_num_correct(model, images, labels):\n",
        "  \"\"\"Compute number of correctly classified images in a batch.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Number of correctly classified images.\n",
        "  \"\"\"\n",
        "  class_logits = model(images, training=False)\n",
        "  return tf.reduce_sum(\n",
        "      tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),\n",
        "              tf.float32)), tf.argmax(class_logits, -1), tf.argmax(labels, -1)"
      ],
      "metadata": {
        "id": "vygnSV4yRvB8"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, compute_loss_fn):\n",
        "  \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # your code start from here for step 4\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "  for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    for images, labels in mnist_train:\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4\n",
        "        logits = model(images, training=True)\n",
        "        loss_value = compute_loss_fn(labels,logits)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = builder.info.splits['test'].num_examples\n",
        "    for images, labels in mnist_test:\n",
        "      # your code start from here for step 4\n",
        "      num_correct += compute_num_correct(model.images,labels)\n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n"
      ],
      "metadata": {
        "id": "EtoLbp8uQ4Vl"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate(teacher2,tf.keras.losses.CategoricalCrossentropy(from_logits=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ex0TwES_0yv",
        "outputId": "2444251d-604b-4152-a862-02d57764885d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training models"
      ],
      "metadata": {
        "id": "NQL1lJdaRPT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code start from here for step 5 \n",
        "\n"
      ],
      "metadata": {
        "id": "-AGHbyABRPz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test accuracy vs. tempreture curve"
      ],
      "metadata": {
        "id": "sj1N38fnRTNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code start from here for step 6\n"
      ],
      "metadata": {
        "id": "gX4dbazrRWIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train student from scratch"
      ],
      "metadata": {
        "id": "WNrH_1emRbGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build fully connected student.\n",
        "fc_model_no_distillation = tf.keras.Sequential()\n",
        "\n",
        "# your code start from here for step 7\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_plain_cross_entropy_loss(images, labels):\n",
        "  \"\"\"Compute plain loss for given images and labels.\n",
        "\n",
        "  For fair comparison and convenience, this function also performs a\n",
        "  LogSumExp over classes, but does not perform class distillation.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  # your code start from here for step 7\n",
        "\n",
        "  student_class_logits = fc_model_no_distillation(images, training=True)\n",
        "  cross_entropy_loss =  tf.keras.losses.categorical_crossentropy(labels, student_class_logits, from_logits=True)\n",
        "  \n",
        "  return cross_entropy_loss\n",
        "\n",
        "\n",
        "train_and_evaluate(fc_model_no_distillation, compute_plain_cross_entropy_loss)"
      ],
      "metadata": {
        "id": "HjospsxIRbQ6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "57b083e4-a876-41ea-8fad-237592851b76"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-5cade0805bd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc_model_no_distillation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_plain_cross_entropy_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_and_evaluate' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing the teacher and student model (number of of parameters and FLOPs) "
      ],
      "metadata": {
        "id": "yq3JTpQ4RuhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code start from here for step 8\n"
      ],
      "metadata": {
        "id": "4V8GB2yRRuxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XAI method to explain models"
      ],
      "metadata": {
        "id": "8b5yNhJfRu-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code start from here for step 9\n"
      ],
      "metadata": {
        "id": "yFgp5kA5RvID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing the state-of-the-art KD algorithm"
      ],
      "metadata": {
        "id": "KjwJ5oziRvRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code start from here for step 13\n"
      ],
      "metadata": {
        "id": "q10lybAFRvZt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}