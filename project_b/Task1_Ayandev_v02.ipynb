{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task1 (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project B: Knowledge Distillation for Building Lightweight Deep Learning Models in Visual Classification Tasks"
      ],
      "metadata": {
        "id": "6WYMfvCNPwpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from typing import Union\n",
        "\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "builder = tfds.builder('mnist')\n",
        "BATCH_SIZE = 256\n",
        "NUM_EPOCHS = 12\n",
        "NUM_CLASSES = 10  # 10 total classes."
      ],
      "metadata": {
        "id": "vA8ppgB2P0aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "#from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "6gnTDdemHLV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading"
      ],
      "metadata": {
        "id": "H2EFLQROP2R7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and test splits.\n",
        "def preprocess(x):\n",
        "  image = tf.image.convert_image_dtype(x['image'], tf.float32)\n",
        "  class_labels = tf.one_hot(x['label'], builder.info.features['label'].num_classes)\n",
        "  return image, class_labels\n",
        "\n",
        "\n",
        "mnist_train = tfds.load('mnist', split='train', shuffle_files=False).cache()\n",
        "mnist_train = mnist_train.map(preprocess)\n",
        "mnist_train = mnist_train.shuffle(builder.info.splits['train'].num_examples)\n",
        "mnist_train = mnist_train.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "mnist_test = tfds.load('mnist', split='test').cache()\n",
        "mnist_test = mnist_test.map(preprocess).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "ynByMG_UP4A4"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yV3LZSMfTtn",
        "outputId": "c6f3ccba-9668-46dc-8b6e-95766f0dd9e4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(256, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model creation"
      ],
      "metadata": {
        "id": "kAZwfvW5P63q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Build CNN teacher.\n",
        "#cnn_model = tf.keras.Sequential()\n",
        "\n",
        "# your code start from here for stpe 2\n",
        "teacher = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\"),\n",
        "        #layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        #layers.Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dropout(0.5),\n",
        "        #layers.Dense(10),\n",
        "        #layers.Dense(10, activation=\"softmax\")\n",
        "        layers.Dense(10)\n",
        "    ],\n",
        "    name=\"teacher\",\n",
        ")\n",
        "\n",
        "\n",
        "# Build fully connected student.\n",
        "#fc_model = tf.keras.Sequential()\n",
        "\n",
        "\n",
        "# your code start from here for step 2\n",
        "\n",
        "student = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(784, activation=\"relu\"),\n",
        "        layers.Dense(784, activation=\"relu\"),\n",
        "        #layers.Dense(10),\n",
        "        #layers.Dense(10, activation=\"softmax\")\n",
        "        layers.Dense(10)\n",
        "        # model.add(Activation('relu'))\n",
        "    ],\n",
        "    name=\"student\",\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zINgDkA7P7BP"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# teacher.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Xr_zY1WwCqpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# student.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NLovqeysCqua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# teacher.fit(mnist_train, epochs=5)\n"
      ],
      "metadata": {
        "id": "zqdH3hz_Dm52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HnQNSu3P3Pb",
        "outputId": "a32ea15c-a293-421b-e67d-08f4f88f0412"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"student\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_7 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 784)               615440    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 784)               615440    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,238,730\n",
            "Trainable params: 1,238,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT4RNtGkCvDY",
        "outputId": "a605faf0-daa3-4afe-ef8e-e0c69b3989d6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"teacher\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " re_lu_8 (ReLU)              (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 28, 28, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " re_lu_9 (ReLU)              (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 128)               1605760   \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,625,866\n",
            "Trainable params: 1,625,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFfPuzb5J0Vu",
        "outputId": "006d558f-ab54-4116-8bb1-2e748147f4f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(256, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the teacher model\n",
        "# teacher.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "N3bzIjUUt94h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# teacher.fit(mnist_train, epochs=5)"
      ],
      "metadata": {
        "id": "1ppTDqa_uA0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher2 = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\"),\n",
        "        #layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        #layers.Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dropout(0.5),\n",
        "        #layers.Dense(10),\n",
        "        #layers.Dense(10, activation=\"softmax\")\n",
        "        layers.Dense(10)\n",
        "    ],\n",
        "    name=\"teacher2\",\n",
        ")"
      ],
      "metadata": {
        "id": "CfKu_WcK4SY0"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unpack data"
      ],
      "metadata": {
        "id": "6yySUuI2Nno_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_example, =mnist_train.take(1)\n",
        "image, label = mnist_example\n"
      ],
      "metadata": {
        "id": "6aScN7bZ5pP6"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teacher loss function"
      ],
      "metadata": {
        "id": "8JWGucyrQGav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def compute_teacher_loss(images, labels):\n",
        "  \"\"\"Compute class knowledge distillation teacher loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  class_logits = teacher(images, training=True)\n",
        "\n",
        "  # Compute cross-entropy loss for classes.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "  cross_entropy_loss_value =tf.reduce_mean(tf.keras.losses.categorical_crossentropy(labels, class_logits, from_logits=True))\n",
        "\n",
        "\n",
        "  return cross_entropy_loss_value"
      ],
      "metadata": {
        "id": "DhzBP6ZLQJ57"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def compute_teacher2_loss(images, labels):\n",
        "  \"\"\"Compute class knowledge distillation teacher loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  class_logits = teacher2(images, training=True)\n",
        "\n",
        "  # Compute cross-entropy loss for classes.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "  cross_entropy_loss_value =tf.reduce_mean(tf.keras.losses.categorical_crossentropy(labels, class_logits, from_logits=True))\n",
        "\n",
        "\n",
        "  return cross_entropy_loss_value"
      ],
      "metadata": {
        "id": "jNltIEBKO8E3"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_wo_hd_loss=compute_teacher_loss(image,label)"
      ],
      "metadata": {
        "id": "YIGHpYLc6r1j"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_wo_hd_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKmqlOcc6t_a",
        "outputId": "11413a15-3c62-4cdd-fadb-c5e5c047de28"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=2.3014956>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = teacher(image, training=True)\n",
        "teacher_wo_conven_loss= tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n"
      ],
      "metadata": {
        "id": "I9WRSE2jKXRV"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xjHCSxEM_BF",
        "outputId": "79ec0e32-9d98-46f1-e5a1-20fb35b0b183"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 10), dtype=float32, numpy=\n",
              "array([[-0.1397345 , -0.04447453,  0.12862381, ..., -0.08678841,\n",
              "         0.21981353,  0.09755316],\n",
              "       [-0.02464676, -0.1277153 ,  0.22527118, ...,  0.2484115 ,\n",
              "         0.01940316,  0.11200459],\n",
              "       [-0.09397954,  0.01585651,  0.2389846 , ..., -0.16748519,\n",
              "        -0.07179485,  0.13059744],\n",
              "       ...,\n",
              "       [-0.01045809, -0.11735284,  0.03315504, ..., -0.07616577,\n",
              "         0.06614104, -0.0382463 ],\n",
              "       [-0.01081269,  0.04974911, -0.03781566, ..., -0.05184472,\n",
              "        -0.09699267, -0.05853181],\n",
              "       [-0.18763806, -0.04817468,  0.12804027, ..., -0.00710503,\n",
              "         0.05203816,  0.1680861 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk0cTQXMPf_4",
        "outputId": "752ba35c-c9ff-4ab7-c75c-5c2e317d5426"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 10), dtype=float32, numpy=\n",
              "array([[0., 0., 0., ..., 0., 1., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label.get_shape()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vPEzcc39pWA",
        "outputId": "8d024edc-09e4-4e14-b061-6e28481056cf"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute_teacher_loss(image,label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe3YkWCrPj5W",
        "outputId": "78b6bb4a-5882-4c53-f04e-c4481dba8b9b"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=2.2930107>"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute_teacher2_loss(image,label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy1kqd_SQdPV",
        "outputId": "7993d7b6-14b7-44d7-e599-23b61cb209ad"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=2.3127394>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loass function and optimizer\n",
        "# loss_func = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5) # Low since we are fine-tuning\n"
      ],
      "metadata": {
        "id": "OQx9quoK1NM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# teacher.compile(loss=compute_teacher_loss(), optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "t4JO_RGI0920"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student loss function"
      ],
      "metadata": {
        "id": "JS8xkuH0QbOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Hyperparameters for distillation (need to be tuned).\n",
        "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE = 4. #temperature hyperparameter\n",
        "\n",
        "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
        "                      temperature: Union[float, tf.Tensor]):\n",
        "  \"\"\"Compute distillation loss.\n",
        "\n",
        "  This function computes cross entropy between softened logits and softened\n",
        "  targets. The resulting loss is scaled by the squared temperature so that\n",
        "  the gradient magnitude remains approximately constant as the temperature is\n",
        "  changed. For reference, see Hinton et al., 2014, \"Distilling the knowledge in\n",
        "  a neural network.\"\n",
        "\n",
        "  Args:\n",
        "    teacher_logits: A Tensor of logits provided by the teacher.\n",
        "    student_logits: A Tensor of logits provided by the student, of the same\n",
        "      shape as `teacher_logits`.\n",
        "    temperature: Temperature to use for distillation.\n",
        "\n",
        "  Returns:\n",
        "    A scalar Tensor containing the distillation loss.\n",
        "  \"\"\"\n",
        " # your code start from here for step 3\n",
        "  soft_targets = teacher_logits / temperature\n",
        "\n",
        "  return tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(\n",
        "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
        "\n",
        "def compute_student_loss(images, labels):\n",
        "  \"\"\"Compute class knowledge distillation student loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  student_class_logits = student(images, training=True)\n",
        "\n",
        "  # Compute class distillation loss between student class logits and\n",
        "  # softened teacher class targets probabilities.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  teacher_class_logits = teacher(images, training=False)\n",
        "  distillation_loss_value =distillation_loss(teacher_class_logits,student_class_logits,DISTILLATION_TEMPERATURE)\n",
        "\n",
        "  # Compute cross-entropy loss with hard targets.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  cross_entropy_loss_value = tf.keras.losses.categorical_crossentropy(labels, student_class_logits, from_logits=True)\n",
        "  \n",
        "  total_loss =ALPHA*cross_entropy_loss_value + (1-ALPHA)*distillation_loss_value\n",
        "\n",
        "  return total_loss"
      ],
      "metadata": {
        "id": "lDKia4gPQMIr"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and evaluation"
      ],
      "metadata": {
        "id": "RJ1uyvurQ3w4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def compute_num_correct(model, images, labels):\n",
        "  \"\"\"Compute number of correctly classified images in a batch.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Number of correctly classified images.\n",
        "  \"\"\"\n",
        "  class_logits = model(images, training=False)\n",
        "  return tf.reduce_sum(\n",
        "      tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),\n",
        "              tf.float32)), tf.argmax(class_logits, -1), tf.argmax(labels, -1)"
      ],
      "metadata": {
        "id": "vygnSV4yRvB8"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, compute_loss_fn):\n",
        "  \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # your code start from here for step 4\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "  for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    for images, labels in mnist_train:\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4\n",
        "        logits = model(images, training=True)\n",
        "        loss_value = tf.reduce_mean(compute_loss_fn(labels,logits,from_logits=True))\n",
        "        # loss_value = compute_loss_fn\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "      train_acc_metric.update_state(labels, logits)\n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = builder.info.splits['test'].num_examples\n",
        "    # for images, labels in mnist_test:\n",
        "      # your code start from here for step 4\n",
        "    print(\"Training loss : %.4f\" % (float(loss_value)))\n",
        "    #   num_correct += compute_num_correct(model,images,labels)\n",
        "    # print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "    #     num_correct / num_total * 100))\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "\n",
        "    # Reset training metrics at the end of each epoch\n",
        "    train_acc_metric.reset_states()"
      ],
      "metadata": {
        "id": "EtoLbp8uQ4Vl"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc_metric = keras.metrics.CategoricalAccuracy()\n",
        "logits = teacher(image, training=True)\n",
        "\n",
        "train_and_evaluate(teacher,tf.keras.losses.categorical_crossentropy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ex0TwES_0yv",
        "outputId": "d0923f7d-0725-41f0-91f6-b99a992296f5"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Training loss : 1.4006\n",
            "Training acc over epoch: 0.4195\n",
            "Epoch 2: Training loss : 0.9280\n",
            "Training acc over epoch: 0.6909\n",
            "Epoch 3: Training loss : 0.7246\n",
            "Training acc over epoch: 0.7699\n",
            "Epoch 4: Training loss : 0.6009\n",
            "Training acc over epoch: 0.8103\n",
            "Epoch 5: Training loss : 0.5128\n",
            "Training acc over epoch: 0.8349\n",
            "Epoch 6: Training loss : 0.4921\n",
            "Training acc over epoch: 0.8504\n",
            "Epoch 7: Training loss : 0.4141\n",
            "Training acc over epoch: 0.8636\n",
            "Epoch 8: Training loss : 0.3289\n",
            "Training acc over epoch: 0.8747\n",
            "Epoch 9: Training loss : 0.4116\n",
            "Training acc over epoch: 0.8828\n",
            "Epoch 10: Training loss : 0.3446\n",
            "Training acc over epoch: 0.8892\n",
            "Epoch 11: Training loss : 0.2574\n",
            "Training acc over epoch: 0.8963\n",
            "Epoch 12: Training loss : 0.3591\n",
            "Training acc over epoch: 0.9036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t=compute_num_correct(teacher,image,label)[0]"
      ],
      "metadata": {
        "id": "YSJXRyXa6I_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nolLOm6uEquD",
        "outputId": "b48ddc33-f1df-4f0d-899b-191fa3e1f0b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=228.0>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate2(model, compute_loss_fn):\n",
        "  \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # your code start from here for step 4\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "  for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    for images, labels in mnist_train:\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4\n",
        "        \n",
        "        loss_value = compute_loss_fn(images,labels)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "      \n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = builder.info.splits['test'].num_examples\n",
        "    for images, labels in mnist_test:\n",
        "    #   # your code start from here for step 4\n",
        "\n",
        "      num_correct += compute_num_correct(model,images,labels)[0]\n",
        "      \n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K6peJymJ3g5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_total = builder.info.splits['test'].num_examples"
      ],
      "metadata": {
        "id": "PRQa_Vk6L1LJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LayQUDSHL517",
        "outputId": "cf812cd0-eb81-4717-ee75-dd8d89b67f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate2(teacher2,compute_teacher_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rzVNikKR52PR",
        "outputId": "260e8157-dd88-4272-abb7-fec6c29237d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: "
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-7b584324f88d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_and_evaluate2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcompute_teacher_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-57-04e0403073e6>\u001b[0m in \u001b[0;36mtrain_and_evaluate2\u001b[0;34m(model, compute_loss_fn)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Run evaluation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreplica\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     \"\"\"\n\u001b[0;32m--> 633\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_empty_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     raise ValueError(f\"No gradients provided for any variable: {variable}. \"\n\u001b[0m\u001b[1;32m     74\u001b[0m                      f\"Provided `grads_and_vars` is {grads_and_vars}.\")\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: (['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'conv2d/kernel:0' shape=(3, 3, 1, 32) dtype=float32, numpy=\narray([[[[ 0.07988951, -0.13545561,  0.09779942, -0.0113201 ,\n          -0.04098444, -0.08363776, -0.05602255,  0.1266913 ,\n          -0.07202975, -0.04290917, -0.01884563, -0.02566583,\n           0.0915283 , -0.1254642 ,  0.11513455,  0.1376519 ,\n           0.09500398,  0.04581197, -0.09715258,  0.13374157,\n           0.07344919,  0.11099203,  0.08420838, -0.12916856,\n           0.07737337,  0.09472495,  0.126206  , -0.07785004,\n           0.01196495,  0.06930867, -0.10257401,  0.02096827]],\n\n        [[-0.03093352, -0.05186576,  0.04542375, -0.06531446,\n          -0.13292716, -0.08255214,  0.00372906, -0.03094094,\n           0.11212663,  0.09537064,  0.12140621, -0.06362596,\n           0.09014125,  0.01626897, -0.1263501 , -0.01746981,\n          -0.127708  ,  0.08403647,  0.02700727,  0.0023289 ,\n           0.02621213, -0.00505294,  0.09321982, -0.04861183,\n           0.14099781,  0.0217022 ,  0.12865956, -0.0525841 ,\n          -0.13631669,  0.12193502, -0.02811246, -0.04352605]],\n\n        [[-0.05544027, -0.01603316,  0.13130887, -0.12680322,\n          -0.08959017, -0.04770501,  0.07203928, -0.13158312,\n          -0.12123264,  0.08579181, -0.0289095 ,  0.03722413,\n          -0.13162538, -0.00050926, -0.02635077,  0.13436122,\n          -0.13925573, -0.10418389, -0.11414694, -0.00154604,\n           0.10773748, -0.10167897,  0.06313494,  0.13398461,\n           0.10767825,  0.02608427,  0.09178007, -0.06606697,\n          -0.0775891 ,  0.04118223,  0.11130629, -0.10084646]]],\n\n\n       [[[ 0.05145274,  0.01456058, -0.00319713, -0.08838473,\n           0.03578575,  0.1227694 , -0.04497559, -0.05241586,\n           0.10347286,  0.00169708,  0.00706117, -0.08328068,\n           0.13058709, -0.09762248, -0.13035671, -0.11976559,\n           0.07706165,  0.05660975,  0.12649722,  0.11156841,\n           0.03979082,  0.10777517,  0.02954936,  0.04855391,\n           0.13132592, -0.04803849, -0.07092675, -0.08935685,\n          -0.09769331, -0.05689719, -0.01374938, -0.01377179]],\n\n        [[ 0.02723773, -0.05904853, -0.02281618, -0.10678793,\n           0.08617917, -0.03315266, -0.13122442, -0.09342107,\n           0.1284798 ,  0.0011542 , -0.01315527,  0.07800266,\n          -0.06575829, -0.08262639,  0.09058805, -0.11550501,\n           0.02951218,  0.12837718, -0.12113759, -0.01552241,\n          -0.0870637 ,  0.0095931 ,  0.03928268,  0.09318772,\n           0.03231138,  0.12114345,  0.0935412 , -0.10529306,\n          -0.10453984,  0.00147495, -0.12286805,  0.12780403]],\n\n        [[ 0.0114302 ,  0.08890022,  0.09650177,  0.00552109,\n          -0.062595  , -0.14042434, -0.01916035,  0.14148675,\n          -0.14211959, -0.09201291,  0.10779753,  0.06266183,\n          -0.02611894, -0.06910633,  0.13093804,  0.06869377,\n          -0.04962964,  0.13006298, -0.01170683, -0.12021084,\n          -0.05056632,  0.00850318, -0.05559954, -0.14107338,\n           0.10385214, -0.12322421,  0.08565006, -0.06519061,\n          -0.06075814,  0.00675645,  0.12207107, -0.00045344]]],\n\n\n       [[[-0.09593812, -0.0195758 ,  0.08728309,  0.0188417 ,\n          -0.10098767, -0.05721437, -0.04298081, -0.07145149,\n          -0.07746043, -0.02420156,  0.00051017, -0.05924151,\n          -0.06596409, -0.11559834, -0.1079218 ,  0.05146559,\n          -0.0733033 , -0.0035903 , -0.01768882, -0.11584161,\n          -0.05376318,  0.07084484, -0.05753685, -0.08690517,\n           0.06840727, -0.13136469, -0.10373665,  0.00118874,\n           0.10771862, -0.05583319, -0.10447098, -0.1024189 ]],\n\n        [[ 0.0266483 ,  0.11104165, -0.10230961,  0.05105101,\n           0.09193301, -0.12420111, -0.02986695,  0.03649975,\n           0.11031298,  0.0001628 , -0.09413616, -0.04831461,\n          -0.03384766,  0.05482067,  0.08737293, -0.08527682,\n          -0.11259513,  0.12972157,  0.08773975,  0.05357857,\n          -0.11338274, -0.07596119, -0.02674321, -0.00963898,\n          -0.0885395 ,  0.10005224, -0.09985241,  0.04835476,\n          -0.0160297 ,  0.00368796,  0.02265647, -0.05335386]],\n\n        [[-0.11903007, -0.11672129, -0.06945211, -0.077259  ,\n           0.09809047,  0.08686577, -0.01856769,  0.10577042,\n          -0.10788581,  0.0852913 , -0.08336896, -0.0419325 ,\n          -0.08096696,  0.01537113, -0.0895372 , -0.05958859,\n          -0.00407167,  0.04019253,  0.03031076, -0.1348698 ,\n           0.12877916, -0.1326621 , -0.08396664,  0.08135544,\n           0.05201232,  0.05075842, -0.05043057, -0.14199387,\n           0.09954725,  0.0820484 ,  0.10021386, -0.04677968]]]],\n      dtype=float32)>), (None, <tf.Variable 'conv2d/bias:0' shape=(32,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>), (None, <tf.Variable 'conv2d_1/kernel:0' shape=(3, 3, 32, 64) dtype=float32, numpy=\narray([[[[ 4.57716659e-02, -5.91102652e-02, -5.86471781e-02, ...,\n           8.23252872e-02,  6.40815571e-02,  5.97495511e-02],\n         [-6.64830059e-02,  3.66503000e-03,  6.76885620e-02, ...,\n          -3.80519629e-02, -4.03065905e-02,  2.42360011e-02],\n         [-3.96981835e-02,  5.61695173e-02,  2.51458660e-02, ...,\n          -5.81337623e-02, -4.84739952e-02, -3.41409072e-02],\n         ...,\n         [ 3.11971307e-02,  5.80170229e-02,  7.11454526e-02, ...,\n          -1.16025209e-02, -1.45987868e-02, -2.30486803e-02],\n         [-8.11031461e-02,  3.04541588e-02, -7.24966750e-02, ...,\n           1.63990483e-02, -6.47604465e-02,  6.89916238e-02],\n         [-5.25678806e-02,  4.46819738e-02, -5.12924790e-02, ...,\n           3.31590176e-02, -5.54757528e-02, -2.84702592e-02]],\n\n        [[ 5.42032346e-02, -3.84673700e-02, -2.56776437e-02, ...,\n           1.01514906e-03, -4.65811715e-02, -1.36186257e-02],\n         [ 6.11918941e-02, -1.79870129e-02,  4.06098142e-02, ...,\n           2.65062824e-02, -7.70265907e-02, -5.68413734e-02],\n         [ 3.28503624e-02,  2.36346945e-02,  5.53823784e-02, ...,\n          -2.63053998e-02,  4.42769304e-02,  1.11202225e-02],\n         ...,\n         [-5.51990084e-02, -9.49469954e-03,  6.17267862e-02, ...,\n          -4.68119606e-02, -7.71269202e-02,  1.49961114e-02],\n         [ 1.74018368e-02, -5.76723032e-02,  8.10808316e-02, ...,\n           2.91422233e-02, -6.63708299e-02,  1.46375299e-02],\n         [-7.42497295e-03, -3.20987329e-02, -3.47599611e-02, ...,\n          -5.81526756e-02, -3.37708592e-02, -2.72253975e-02]],\n\n        [[ 6.13489822e-02, -1.58805475e-02, -6.99446648e-02, ...,\n           3.14632878e-02,  7.28347152e-03, -6.77637085e-02],\n         [-1.28120184e-02,  1.84369087e-02,  4.28484902e-02, ...,\n          -1.51631236e-02,  1.65260658e-02, -7.64491409e-03],\n         [-3.66819128e-02,  6.68105856e-02, -5.45398146e-03, ...,\n          -1.48868561e-02, -2.91268453e-02,  5.59330359e-02],\n         ...,\n         [-3.74161229e-02,  1.31958723e-03,  5.76940998e-02, ...,\n          -4.57892045e-02, -3.21930870e-02, -1.59401298e-02],\n         [ 2.71370187e-02, -6.02145791e-02,  8.03620592e-02, ...,\n           3.93246636e-02,  1.92884579e-02, -5.62095046e-02],\n         [-3.49231176e-02, -5.86533174e-02,  8.23915973e-02, ...,\n          -7.32470006e-02, -2.46239528e-02,  5.87632507e-03]]],\n\n\n       [[[-4.61757183e-04, -6.61627501e-02,  7.37836733e-02, ...,\n          -1.33034959e-02,  2.44454145e-02, -3.81777436e-03],\n         [ 6.44035712e-02,  1.15365759e-02,  4.93977293e-02, ...,\n          -1.62582025e-02,  1.86006799e-02,  4.68698367e-02],\n         [ 2.39574909e-03,  6.56211004e-02, -3.30950841e-02, ...,\n           8.10600892e-02,  6.73718676e-02,  3.10543776e-02],\n         ...,\n         [-7.08487630e-02, -1.07005835e-02, -5.68675995e-03, ...,\n           6.06105402e-02, -3.08013558e-02, -4.40746956e-02],\n         [-7.55809769e-02,  4.53676358e-02, -8.52143764e-03, ...,\n           1.98505744e-02, -4.49674949e-02,  2.91405320e-02],\n         [ 8.07776302e-03, -2.02623382e-02,  2.26925015e-02, ...,\n          -5.32616377e-02,  2.61209607e-02, -1.23385563e-02]],\n\n        [[-2.94518471e-03, -1.20014548e-02,  5.33184186e-02, ...,\n           6.36149123e-02, -7.33321905e-03,  6.52178004e-02],\n         [-4.39201221e-02,  8.56175274e-03, -2.86904797e-02, ...,\n           1.49660110e-02, -7.61764646e-02,  3.33986431e-03],\n         [-1.32968426e-02,  3.39071751e-02,  2.95961276e-02, ...,\n           2.50949040e-02, -7.44581074e-02, -3.56780514e-02],\n         ...,\n         [ 1.14123225e-02,  7.70707354e-02, -4.41892371e-02, ...,\n          -4.24398594e-02, -4.79016528e-02,  5.11705950e-02],\n         [ 1.55856386e-02,  8.01388174e-03,  7.12977126e-02, ...,\n          -5.36348820e-02, -1.55846849e-02,  5.50774410e-02],\n         [ 6.64523989e-03, -2.11485624e-02,  2.95836553e-02, ...,\n          -5.69424033e-02,  5.88304624e-02,  6.41398206e-02]],\n\n        [[ 4.89359573e-02,  6.04525954e-03, -7.47319907e-02, ...,\n          -8.13165531e-02, -4.87015061e-02,  4.42674384e-02],\n         [ 3.21132764e-02,  4.46657017e-02,  3.21673378e-02, ...,\n           4.61925343e-02, -7.82472119e-02,  7.41914660e-03],\n         [ 3.02413926e-02, -5.62251024e-02,  7.17982873e-02, ...,\n          -4.00926918e-03,  3.94318923e-02,  7.62211308e-02],\n         ...,\n         [ 1.23607293e-02, -5.13762645e-02,  1.64557323e-02, ...,\n           3.05581465e-02, -3.34059820e-02,  2.41611823e-02],\n         [-6.08782992e-02, -5.24690151e-02,  4.72604856e-02, ...,\n          -6.66415542e-02,  6.49679974e-02,  1.03835016e-03],\n         [ 3.31347585e-02, -7.63017163e-02, -2.17141733e-02, ...,\n           7.86915049e-02,  5.61676100e-02, -2.56541371e-02]]],\n\n\n       [[[ 4.05344963e-02,  5.95200285e-02, -5.48469648e-02, ...,\n           2.20942721e-02, -2.42675170e-02, -3.53250727e-02],\n         [ 2.16195807e-02,  3.31870317e-02,  8.00561085e-02, ...,\n          -5.75700216e-02,  4.24497500e-02, -8.05961713e-02],\n         [ 7.38052204e-02, -3.89027596e-02,  4.27224413e-02, ...,\n           2.23433003e-02, -8.12542886e-02, -2.64444351e-02],\n         ...,\n         [ 1.69869885e-02, -1.83428153e-02, -5.78286462e-02, ...,\n           1.73258185e-02,  2.97557488e-02, -6.55896887e-02],\n         [ 4.91833687e-03, -5.49190044e-02,  3.30392346e-02, ...,\n          -6.43864125e-02,  6.94563240e-03,  5.65472990e-03],\n         [ 6.27420917e-02,  2.51602307e-02,  1.66346654e-02, ...,\n           3.75199318e-02, -7.04703480e-03,  1.81653500e-02]],\n\n        [[ 6.37208000e-02,  1.17865801e-02,  8.05443004e-02, ...,\n          -3.33928280e-02, -3.97018790e-02, -6.38522357e-02],\n         [ 2.50801221e-02,  5.73737696e-02,  6.50318339e-02, ...,\n          -2.56227478e-02,  1.27409324e-02,  1.62039995e-02],\n         [ 4.41725329e-02,  5.93900159e-02,  4.90630344e-02, ...,\n           3.59181389e-02, -7.94235691e-02, -7.69815668e-02],\n         ...,\n         [-3.46350074e-02, -4.88104671e-03,  3.16729918e-02, ...,\n           1.54933706e-02,  9.47022438e-03,  7.39322081e-02],\n         [-1.59549490e-02, -3.83573398e-02, -3.31526212e-02, ...,\n          -6.78945631e-02,  2.90280357e-02,  1.02376342e-02],\n         [-4.16341424e-02,  2.57948041e-02,  7.84807876e-02, ...,\n          -4.09523249e-02,  3.63873020e-02,  3.98222208e-02]],\n\n        [[-3.10079865e-02, -8.06674361e-05, -5.37755303e-02, ...,\n          -5.27061038e-02, -5.89728355e-03, -1.20016113e-02],\n         [ 5.69020286e-02,  7.86390081e-02,  4.99466807e-03, ...,\n          -4.83224019e-02,  4.45450023e-02,  7.79742673e-02],\n         [ 4.31663767e-02, -6.79268464e-02, -6.48025721e-02, ...,\n           6.67194203e-02, -7.64462799e-02,  4.37342897e-02],\n         ...,\n         [ 8.66723061e-03, -7.70441517e-02,  2.49964967e-02, ...,\n          -7.40297437e-02,  4.71798554e-02,  3.94903049e-02],\n         [-7.96014071e-02,  6.95307031e-02, -3.21644954e-02, ...,\n          -1.90710425e-02,  7.40273818e-02, -5.95221333e-02],\n         [-7.61593804e-02, -7.46213421e-02, -3.00749540e-02, ...,\n           3.29715982e-02, -5.04670553e-02,  4.16183472e-03]]]],\n      dtype=float32)>), (None, <tf.Variable 'conv2d_1/bias:0' shape=(64,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense/kernel:0' shape=(12544, 128) dtype=float32, numpy=\narray([[ 0.01970283,  0.01824867,  0.01850845, ...,  0.01132801,\n        -0.01007856, -0.00473607],\n       [-0.00565183, -0.00120099,  0.00402679, ..., -0.00348439,\n        -0.01456857,  0.00812819],\n       [-0.01488707,  0.0148431 , -0.0187894 , ..., -0.00114903,\n        -0.01673503, -0.01412885],\n       ...,\n       [ 0.00798265,  0.00102754,  0.01557823, ..., -0.01793949,\n         0.02169483,  0.00936801],\n       [ 0.00699825, -0.01007688, -0.01634112, ...,  0.00478938,\n        -0.00931041,  0.00695035],\n       [ 0.00853548, -0.01545573,  0.01517574, ...,  0.01790234,\n        -0.00387408,  0.02103422]], dtype=float32)>), (None, <tf.Variable 'dense/bias:0' shape=(128,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'dense_1/kernel:0' shape=(128, 10) dtype=float32, numpy=\narray([[-0.04891784, -0.06243998,  0.00125259, ...,  0.13953988,\n         0.01595859, -0.02221809],\n       [-0.09882136,  0.02423085,  0.01414703, ...,  0.11562632,\n         0.19252633,  0.13022979],\n       [-0.01313625, -0.12666312, -0.13671306, ..., -0.11093047,\n        -0.07801344, -0.06893626],\n       ...,\n       [-0.03427924, -0.18463816, -0.0325588 , ...,  0.18150143,\n         0.07732485,  0.04833536],\n       [-0.04616012,  0.16701652,  0.15883301, ...,  0.00272918,\n         0.19530304, -0.16373454],\n       [ 0.14544512,  0.11476634, -0.0223913 , ...,  0.1443898 ,\n        -0.12248647, -0.01123872]], dtype=float32)>), (None, <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>))."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training models"
      ],
      "metadata": {
        "id": "NQL1lJdaRPT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code start from here for step 5 \n",
        "\n"
      ],
      "metadata": {
        "id": "-AGHbyABRPz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test accuracy vs. tempreture curve"
      ],
      "metadata": {
        "id": "sj1N38fnRTNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code start from here for step 6\n"
      ],
      "metadata": {
        "id": "gX4dbazrRWIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train student from scratch"
      ],
      "metadata": {
        "id": "WNrH_1emRbGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build fully connected student.\n",
        "fc_model_no_distillation = tf.keras.Sequential()\n",
        "\n",
        "# your code start from here for step 7\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_plain_cross_entropy_loss(images, labels):\n",
        "  \"\"\"Compute plain loss for given images and labels.\n",
        "\n",
        "  For fair comparison and convenience, this function also performs a\n",
        "  LogSumExp over classes, but does not perform class distillation.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  # your code start from here for step 7\n",
        "\n",
        "  student_class_logits = fc_model_no_distillation(images, training=True)\n",
        "  cross_entropy_loss =  tf.keras.losses.categorical_crossentropy(labels, student_class_logits, from_logits=True)\n",
        "  \n",
        "  return cross_entropy_loss\n",
        "\n",
        "\n",
        "train_and_evaluate(fc_model_no_distillation, compute_plain_cross_entropy_loss)"
      ],
      "metadata": {
        "id": "HjospsxIRbQ6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "57b083e4-a876-41ea-8fad-237592851b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-5cade0805bd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc_model_no_distillation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_plain_cross_entropy_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_and_evaluate' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing the teacher and student model (number of of parameters and FLOPs) "
      ],
      "metadata": {
        "id": "yq3JTpQ4RuhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code start from here for step 8\n"
      ],
      "metadata": {
        "id": "4V8GB2yRRuxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XAI method to explain models"
      ],
      "metadata": {
        "id": "8b5yNhJfRu-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code start from here for step 9\n"
      ],
      "metadata": {
        "id": "yFgp5kA5RvID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing the state-of-the-art KD algorithm"
      ],
      "metadata": {
        "id": "KjwJ5oziRvRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code start from here for step 13\n"
      ],
      "metadata": {
        "id": "q10lybAFRvZt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}