{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WYMfvCNPwpm"
   },
   "source": [
    "# Project B: Knowledge Distillation for Building Lightweight Deep Learning Models in Visual Classification Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "vA8ppgB2P0aJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from typing import Union\n",
    "\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "builder = tfds.builder('mnist')\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 12\n",
    "NUM_CLASSES = 10  # 10 total classes.\n",
    "\n",
    "# Not originally included\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "ENTROPY_ZERO_FILLER = 1e-15\n",
    "NUM_CLASSES = 2 #SSA or HP\n",
    "WEIGHT_DECAY = 5e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2EFLQROP2R7"
   },
   "source": [
    "## Data loading/augmenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2176 images belonging to 2 classes.\n",
      "Found 976 images belonging to 2 classes.\n",
      "(array([[[[0.7842671 , 0.6063359 , 0.7762172 ],\n",
      "         [0.7860314 , 0.6082515 , 0.7773262 ],\n",
      "         [0.8075136 , 0.6302881 , 0.7876909 ],\n",
      "         ...,\n",
      "         [0.61543876, 0.42457235, 0.6388687 ],\n",
      "         [0.65154874, 0.44940823, 0.6786403 ],\n",
      "         [0.52542275, 0.36240715, 0.6184585 ]],\n",
      "\n",
      "        [[0.75464535, 0.55239505, 0.7419674 ],\n",
      "         [0.7533851 , 0.5516389 , 0.7416145 ],\n",
      "         [0.80159956, 0.6255937 , 0.7806602 ],\n",
      "         ...,\n",
      "         [0.618838  , 0.42702428, 0.6409862 ],\n",
      "         [0.6475922 , 0.4465105 , 0.6768014 ],\n",
      "         [0.5269831 , 0.36374456, 0.6191272 ]],\n",
      "\n",
      "        [[0.83653533, 0.6506643 , 0.7909347 ],\n",
      "         [0.83572876, 0.6487992 , 0.78997695],\n",
      "         [0.8756891 , 0.75205815, 0.84797704],\n",
      "         ...,\n",
      "         [0.5549314 , 0.3809961 , 0.61192864],\n",
      "         [0.5341586 , 0.3668991 , 0.60647553],\n",
      "         [0.42290118, 0.28249508, 0.53915805]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.95780325, 0.954928  , 0.9576289 ],\n",
      "         [0.95760643, 0.95237446, 0.95561457],\n",
      "         [0.9568628 , 0.95374274, 0.9558228 ],\n",
      "         ...,\n",
      "         [0.93810254, 0.9364073 , 0.9485339 ],\n",
      "         [0.9388962 , 0.9356137 , 0.95294124],\n",
      "         [0.9389466 , 0.9355633 , 0.95294124]],\n",
      "\n",
      "        [[0.9590796 , 0.954646  , 0.95856756],\n",
      "         [0.95856786, 0.95515776, 0.9568628 ],\n",
      "         [0.9568628 , 0.9568628 , 0.9568628 ],\n",
      "         ...,\n",
      "         [0.9361994 , 0.93852973, 0.95149964],\n",
      "         [0.93725497, 0.9395349 , 0.95294124],\n",
      "         [0.93725497, 0.9394845 , 0.95294124]],\n",
      "\n",
      "        [[0.95913535, 0.95459026, 0.9585118 ],\n",
      "         [0.9585121 , 0.9552135 , 0.9568628 ],\n",
      "         [0.9568628 , 0.9568628 , 0.9568628 ],\n",
      "         ...,\n",
      "         [0.9428096 , 0.9378629 , 0.9508967 ],\n",
      "         [0.9463731 , 0.93661743, 0.95294124],\n",
      "         [0.94617146, 0.9367183 , 0.95294124]]],\n",
      "\n",
      "\n",
      "       [[[0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         ...,\n",
      "         [0.8977779 , 0.81638706, 0.9429126 ],\n",
      "         [0.82520366, 0.7293147 , 0.87564653],\n",
      "         [0.46903262, 0.3676659 , 0.5233405 ]],\n",
      "\n",
      "        [[0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         ...,\n",
      "         [0.9053894 , 0.8223302 , 0.95262486],\n",
      "         [0.7993978 , 0.7012386 , 0.8504983 ],\n",
      "         [0.4051104 , 0.30245054, 0.45893198]],\n",
      "\n",
      "        [[0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         ...,\n",
      "         [0.8889488 , 0.803259  , 0.93684185],\n",
      "         [0.73166245, 0.6328456 , 0.78342056],\n",
      "         [0.37683254, 0.2669388 , 0.41947448]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9044393 , 0.89659613, 0.92012554],\n",
      "         [0.898363  , 0.89051986, 0.91404927],\n",
      "         [0.9314933 , 0.92365015, 0.94717956],\n",
      "         ...,\n",
      "         [0.58034325, 0.47849005, 0.61531466],\n",
      "         [0.67586833, 0.5766686 , 0.70287937],\n",
      "         [0.7713935 , 0.6748472 , 0.79044396]],\n",
      "\n",
      "        [[0.9024664 , 0.8946233 , 0.9181527 ],\n",
      "         [0.90493923, 0.8970961 , 0.9206255 ],\n",
      "         [0.9282052 , 0.92036206, 0.94389147],\n",
      "         ...,\n",
      "         [0.5353504 , 0.42375055, 0.59384423],\n",
      "         [0.5121325 , 0.40185937, 0.56797284],\n",
      "         [0.48891458, 0.3799682 , 0.5421015 ]],\n",
      "\n",
      "        [[0.90049356, 0.8926504 , 0.91617984],\n",
      "         [0.9115155 , 0.90367234, 0.92720175],\n",
      "         [0.92491704, 0.9170739 , 0.9406033 ],\n",
      "         ...,\n",
      "         [0.54171365, 0.4167753 , 0.6100652 ],\n",
      "         [0.54901075, 0.42672583, 0.6160355 ],\n",
      "         [0.5563078 , 0.43667635, 0.6220058 ]]],\n",
      "\n",
      "\n",
      "       [[[0.79968065, 0.36731365, 0.58306307],\n",
      "         [0.73129666, 0.3559028 , 0.5974788 ],\n",
      "         [0.80275613, 0.33412236, 0.54274344],\n",
      "         ...,\n",
      "         [0.94897515, 0.93721044, 0.9490197 ],\n",
      "         [0.94518715, 0.93342245, 0.9490642 ],\n",
      "         [0.95294124, 0.94117653, 0.95294124]],\n",
      "\n",
      "        [[0.8141083 , 0.4501248 , 0.65806144],\n",
      "         [0.75922364, 0.33377802, 0.53968227],\n",
      "         [0.76403666, 0.3531568 , 0.5781091 ],\n",
      "         ...,\n",
      "         [0.95278233, 0.9410176 , 0.9490625 ],\n",
      "         [0.9488637 , 0.937099  , 0.95278394],\n",
      "         [0.94533175, 0.93356705, 0.94913656]],\n",
      "\n",
      "        [[0.7741302 , 0.34022748, 0.55432427],\n",
      "         [0.57717335, 0.34029666, 0.6029265 ],\n",
      "         [0.501612  , 0.32520702, 0.58797884],\n",
      "         ...,\n",
      "         [0.9528975 , 0.93360406, 0.95282775],\n",
      "         [0.94901836, 0.93725365, 0.9528975 ],\n",
      "         [0.9489028 , 0.9371381 , 0.9490197 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9607844 , 0.9607844 , 0.9606654 ],\n",
      "         [0.9607844 , 0.9607844 , 0.96078306],\n",
      "         [0.9607844 , 0.9607844 , 0.9607844 ],\n",
      "         ...,\n",
      "         [0.72153085, 0.49858254, 0.71776694],\n",
      "         [0.5313135 , 0.3576345 , 0.6188712 ],\n",
      "         [0.5768775 , 0.40044346, 0.6436685 ]],\n",
      "\n",
      "        [[0.9607844 , 0.9607844 , 0.9569818 ],\n",
      "         [0.9607844 , 0.9607844 , 0.96074235],\n",
      "         [0.9607844 , 0.9607844 , 0.9607844 ],\n",
      "         ...,\n",
      "         [0.6086153 , 0.40100074, 0.6437877 ],\n",
      "         [0.5716024 , 0.39489424, 0.64612377],\n",
      "         [0.444719  , 0.2870629 , 0.5641547 ]],\n",
      "\n",
      "        [[0.9607844 , 0.9607844 , 0.9607844 ],\n",
      "         [0.9607844 , 0.9607844 , 0.9607844 ],\n",
      "         [0.9607844 , 0.9607844 , 0.9607844 ],\n",
      "         ...,\n",
      "         [0.63263   , 0.42908144, 0.6725263 ],\n",
      "         [0.5506604 , 0.38140875, 0.6398282 ],\n",
      "         [0.4517357 , 0.3022636 , 0.572949  ]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[0.56908554, 0.43967378, 0.6156863 ],\n",
      "         [0.6790816 , 0.55312157, 0.73649555],\n",
      "         [0.7009974 , 0.5720674 , 0.7701406 ],\n",
      "         ...,\n",
      "         [0.80653554, 0.70140004, 0.85751593],\n",
      "         [0.8044057 , 0.6986616 , 0.8553861 ],\n",
      "         [0.794517  , 0.68792933, 0.84549737]],\n",
      "\n",
      "        [[0.569389  , 0.43997723, 0.6156863 ],\n",
      "         [0.66937166, 0.54310817, 0.72587526],\n",
      "         [0.7003905 , 0.57176393, 0.76862335],\n",
      "         ...,\n",
      "         [0.66246593, 0.54597443, 0.7134463 ],\n",
      "         [0.6502952 , 0.5328909 , 0.7012756 ],\n",
      "         [0.6479523 , 0.53030527, 0.6989327 ]],\n",
      "\n",
      "        [[0.56969243, 0.44028065, 0.6156863 ],\n",
      "         [0.65966165, 0.5330947 , 0.71525496],\n",
      "         [0.6997837 , 0.5714605 , 0.76710624],\n",
      "         ...,\n",
      "         [0.66115737, 0.5435103 , 0.71213776],\n",
      "         [0.6623745 , 0.54472744, 0.7133549 ],\n",
      "         [0.662322  , 0.5444632 , 0.713514  ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.6554615 , 0.5107368 , 0.70569503],\n",
      "         [0.65911263, 0.5146923 , 0.70873773],\n",
      "         [0.6627639 , 0.5186478 , 0.71178037],\n",
      "         ...,\n",
      "         [0.9490197 , 0.9490197 , 0.9490197 ],\n",
      "         [0.94768095, 0.94768095, 0.94768095],\n",
      "         [0.9402958 , 0.9398615 , 0.9407303 ]],\n",
      "\n",
      "        [[0.6998476 , 0.5586711 , 0.74262315],\n",
      "         [0.7013689 , 0.5601924 , 0.7438402 ],\n",
      "         [0.7028902 , 0.56171376, 0.74505734],\n",
      "         ...,\n",
      "         [0.9490197 , 0.9490197 , 0.9490197 ],\n",
      "         [0.9485913 , 0.9485913 , 0.9485913 ],\n",
      "         [0.9381718 , 0.9380408 , 0.9383028 ]],\n",
      "\n",
      "        [[0.71729714, 0.5775204 , 0.756163  ],\n",
      "         [0.716993  , 0.57843316, 0.75555444],\n",
      "         [0.7166887 , 0.57934594, 0.75494593],\n",
      "         ...,\n",
      "         [0.9490197 , 0.9490197 , 0.9490197 ],\n",
      "         [0.9490197 , 0.9490197 , 0.9490197 ],\n",
      "         [0.93777233, 0.93777233, 0.93777233]]],\n",
      "\n",
      "\n",
      "       [[[0.37704116, 0.25030044, 0.48417404],\n",
      "         [0.4275503 , 0.30740133, 0.5227501 ],\n",
      "         [0.52557933, 0.4106025 , 0.59975404],\n",
      "         ...,\n",
      "         [0.98216903, 0.9508149 , 0.9772889 ],\n",
      "         [0.98708487, 0.96194106, 0.9838561 ],\n",
      "         [0.9875364 , 0.962449  , 0.9844205 ]],\n",
      "\n",
      "        [[0.3777977 , 0.25099877, 0.48498875],\n",
      "         [0.4260954 , 0.3058301 , 0.52152795],\n",
      "         [0.5241245 , 0.40908945, 0.59864837],\n",
      "         ...,\n",
      "         [0.9165293 , 0.85897803, 0.91983783],\n",
      "         [0.97462595, 0.92110896, 0.9792394 ],\n",
      "         [0.9740051 , 0.9197544 , 0.97873145]],\n",
      "\n",
      "        [[0.44487768, 0.31647918, 0.5547429 ],\n",
      "         [0.48579854, 0.36485973, 0.582021  ],\n",
      "         [0.61977506, 0.5046818 , 0.6946481 ],\n",
      "         ...,\n",
      "         [0.84295917, 0.7572    , 0.85980177],\n",
      "         [0.92688084, 0.8408395 , 0.9439492 ],\n",
      "         [0.9261471 , 0.8398236 , 0.9434412 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         ...,\n",
      "         [0.45490077, 0.33347788, 0.54887265],\n",
      "         [0.4034625 , 0.28813723, 0.48753053],\n",
      "         [0.4856232 , 0.37565002, 0.5574084 ]],\n",
      "\n",
      "        [[0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         ...,\n",
      "         [0.3775309 , 0.25489417, 0.47271666],\n",
      "         [0.38075626, 0.26596186, 0.4638207 ],\n",
      "         [0.4887668 , 0.38038877, 0.5579291 ]],\n",
      "\n",
      "        [[0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         ...,\n",
      "         [0.37828746, 0.25553432, 0.47358957],\n",
      "         [0.3793014 , 0.2643906 , 0.4626568 ],\n",
      "         [0.48690456, 0.37846833, 0.55612504]]],\n",
      "\n",
      "\n",
      "       [[[0.7680261 , 0.62141234, 0.72640455],\n",
      "         [0.7564625 , 0.6101308 , 0.7145589 ],\n",
      "         [0.7448989 , 0.59884924, 0.7027133 ],\n",
      "         ...,\n",
      "         [0.8027632 , 0.66942984, 0.8302142 ],\n",
      "         [0.8064811 , 0.6731478 , 0.8314204 ],\n",
      "         [0.9431997 , 0.84738976, 0.95171976]],\n",
      "\n",
      "        [[0.79742694, 0.64840734, 0.76122165],\n",
      "         [0.8104007 , 0.6613811 , 0.77363133],\n",
      "         [0.82337445, 0.67435485, 0.7860411 ],\n",
      "         ...,\n",
      "         [0.7901524 , 0.65681905, 0.81760335],\n",
      "         [0.813933  , 0.68059963, 0.8385856 ],\n",
      "         [0.9546642 , 0.86315334, 0.96146446]],\n",
      "\n",
      "        [[0.69673765, 0.55070746, 0.6683545 ],\n",
      "         [0.69476336, 0.5481691 , 0.6658162 ],\n",
      "         [0.6927891 , 0.54563075, 0.6632778 ],\n",
      "         ...,\n",
      "         [0.7775416 , 0.6442082 , 0.80499256],\n",
      "         [0.82138485, 0.6880515 , 0.84575087],\n",
      "         [0.9661285 , 0.8789169 , 0.9712092 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.73572975, 0.5803073 , 0.7132412 ],\n",
      "         [0.6402362 , 0.487295  , 0.6127852 ],\n",
      "         [0.49689904, 0.34395784, 0.46944803],\n",
      "         ...,\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124]],\n",
      "\n",
      "        [[0.7408887 , 0.58575284, 0.71782696],\n",
      "         [0.6121484 , 0.4592072 , 0.5846974 ],\n",
      "         [0.51724833, 0.36430717, 0.48979738],\n",
      "         ...,\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124]],\n",
      "\n",
      "        [[0.7460477 , 0.59119844, 0.72241277],\n",
      "         [0.58406067, 0.43111947, 0.5566097 ],\n",
      "         [0.53759766, 0.38465646, 0.5101466 ],\n",
      "         ...,\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124],\n",
      "         [0.95294124, 0.95294124, 0.95294124]]]], dtype=float32), array([[1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [0., 1.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.],\n",
      "       [1., 0.]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "# Adapted from Project A's HMT Dataset loading code to use the ImageDataGenerator to augment the data and preload labels/image batches\n",
    "\n",
    "img_dir = 'mhist_dataset/images'\n",
    "train_dir = 'mhist_dataset/images/train'\n",
    "test_dir = 'mhist_dataset/images/test'\n",
    "anno_csv = 'mhist_dataset/annotations.csv'\n",
    "\n",
    "\n",
    "if not os.path.isdir(train_dir):\n",
    "    os.mkdir(train_dir)\n",
    "if not os.path.isdir(test_dir):\n",
    "    os.mkdir(test_dir)\n",
    "    \n",
    "if not os.path.isdir(os.path.join(train_dir, '01_HP')):\n",
    "    os.mkdir(os.path.join(train_dir, '01_HP'))\n",
    "if not os.path.isdir(os.path.join(train_dir, '02_SSA')):\n",
    "    os.mkdir(os.path.join(train_dir, '02_SSA'))\n",
    "if not os.path.isdir(os.path.join(test_dir, '01_HP')):\n",
    "    os.mkdir(os.path.join(test_dir, '01_HP'))\n",
    "if not os.path.isdir(os.path.join(test_dir, '02_SSA')):\n",
    "    os.mkdir(os.path.join(test_dir, '02_SSA'))\n",
    "    \n",
    "# load csv\n",
    "# label struct: [HP, SSA]\n",
    "# labels as a list are sorted in alphabetical order as per the csv\n",
    "\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "train_img = []\n",
    "test_img = []\n",
    "\n",
    "with open(anno_csv, 'r') as csvfile:\n",
    "    first_row = True\n",
    "    for row in csv.reader(csvfile):\n",
    "        if first_row:\n",
    "            first_row = False\n",
    "            continue\n",
    "        if row[3] == 'train':\n",
    "            train_img.append(row[0])\n",
    "            if row[1] == 'HP':\n",
    "                train_labels.append([1, 0])\n",
    "            elif row[1] == 'SSA':\n",
    "                train_labels.append([0, 1])\n",
    "        elif row[3] == 'test':\n",
    "            test_img.append(row[0])\n",
    "            if row[1] == 'HP':\n",
    "                test_labels.append([1, 0])\n",
    "            elif row[1] == 'SSA':\n",
    "                test_labels.append([0, 1])\n",
    "        if row[0] in os.listdir(img_dir):\n",
    "            if row[1] == 'HP' and row[3] == 'train':\n",
    "                os.rename(os.path.join(img_dir, row[0]), os.path.join(train_dir, '01_HP', row[0]))\n",
    "            elif row[1] == 'SSA' and row[3] == 'train':\n",
    "                os.rename(os.path.join(img_dir, row[0]), os.path.join(train_dir, '02_SSA', row[0]))\n",
    "            elif row[1] == 'HP' and row[3] == 'test':\n",
    "                os.rename(os.path.join(img_dir, row[0]), os.path.join(test_dir, '01_HP', row[0]))\n",
    "            elif row[1] == 'SSA' and row[3] == 'test':\n",
    "                os.rename(os.path.join(img_dir, row[0]), os.path.join(test_dir, '02_SSA', row[0]))\n",
    "    \n",
    "# Data Augmentation using ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.,\n",
    "shear_range=0.1,\n",
    "rotation_range=15,\n",
    "horizontal_flip=True,\n",
    "vertical_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "class_mode='categorical',\n",
    "interpolation='bilinear',\n",
    "target_size=(224, 224),\n",
    "batch_size=32,\n",
    "shuffle=True)\n",
    "\n",
    "# changed batch size to 62 from 32\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "class_mode='categorical',\n",
    "interpolation='bilinear',\n",
    "target_size=(224, 224),\n",
    "batch_size=62,\n",
    "shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAZwfvW5P63q",
    "tags": []
   },
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zINgDkA7P7BP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, None, None, 2048)  23564800  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, None, None, 2)     4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,568,898\n",
      "Trainable params: 23,523,458\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n",
      "9420800/9406464 [==============================] - 0s 0us/step\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, None, None, 1280)  2257984  \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, None, None, 2)     2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,226,434\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, None, None, 1280)  2257984  \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, None, None, 2)     2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,226,434\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#@test {\"output\": \"ignore\"}\n",
    "# citing https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet50V2, https://www.kaggle.com/code/suniliitb96/tutorial-keras-transfer-learning-with-resnet50/notebook,\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v2/MobileNetV2 and https://github.com/Abhi-T/MNIST-CLASSIFIER-From-Scratch/blob/main/MNIST__handwritten_digit_Model.ipynb\n",
    "\n",
    "# Build CNN teacher.\n",
    "\n",
    "teacher_model = tf.keras.Sequential()\n",
    "\n",
    "# your code start from here for step 2\n",
    "\n",
    "teacher_model.add(tf.keras.applications.resnet_v2.ResNet50V2(include_top = False, classifier_activation = None))\n",
    "teacher_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(teacher_model.summary())\n",
    "\n",
    "# Build fully connected students\n",
    "student_kd_model = tf.keras.Sequential()\n",
    "student_kd_model.add(tf.keras.applications.mobilenet_v2.MobileNetV2(include_top = False, classifier_activation = None))\n",
    "student_kd_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(student_kd_model.summary())\n",
    "\n",
    "student_scratch_model = tf.keras.Sequential()\n",
    "student_scratch_model.add(tf.keras.applications.mobilenet_v2.MobileNetV2(include_top = False, classifier_activation = None))\n",
    "student_scratch_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(student_scratch_model.summary())\n",
    "\n",
    "\n",
    "# your code start from here for step 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JWGucyrQGav",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Teacher loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DhzBP6ZLQJ57"
   },
   "outputs": [],
   "source": [
    "def compute_teacher_loss(images, labels):\n",
    "    \"\"\"Compute class knowledge distillation teacher loss for given images\n",
    "     and labels.\n",
    "\n",
    "    Args:\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "\n",
    "    Returns:\n",
    "    Scalar loss Tensor.\n",
    "    \"\"\"\n",
    "    # already in probability form\n",
    "    class_logits = cnn_model(images, training=True)\n",
    "\n",
    "    # Compute cross-entropy loss for classes.\n",
    "\n",
    "    # your code start from here for step 3\n",
    "    \n",
    "    cross_entropy_loss_value = tf.keras.losses.categorical_crossentropy(labels, tf.nn.softmax(class_logits))\n",
    "\n",
    "    return cross_entropy_loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JS8xkuH0QbOS",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Student loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDKia4gPQMIr"
   },
   "outputs": [],
   "source": [
    "# adapted from https://keras.io/examples/vision/knowledge_distillation/\n",
    "\n",
    "#@test {\"output\": \"ignore\"}\n",
    "\n",
    "# Hyperparameters for distillation (need to be tuned).\n",
    "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
    "DISTILLATION_TEMPERATURE = 4. #temperature hyperparameter\n",
    "\n",
    "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
    "                      temperature: Union[float, tf.Tensor]):\n",
    "    \"\"\"Compute distillation loss.\n",
    "\n",
    "    This function computes cross entropy between softened logits and softened\n",
    "    targets. The resulting loss is scaled by the squared temperature so that\n",
    "    the gradient magnitude remains approximately constant as the temperature is\n",
    "    changed. For reference, see Hinton et al., 2014, \"Distilling the knowledge in\n",
    "    a neural network.\"\n",
    "\n",
    "    Args:\n",
    "    teacher_logits: A Tensor of logits provided by the teacher.\n",
    "    student_logits: A Tensor of logits provided by the student, of the same\n",
    "      shape as `teacher_logits`.\n",
    "    temperature: Temperature to use for distillation.\n",
    "\n",
    "    Returns:\n",
    "    A scalar Tensor containing the distillation loss.\n",
    "    \"\"\"\n",
    "    # your code start from here for step 3\n",
    "    soft_targets = teacher_logits / temperature\n",
    "\n",
    "    return tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(\n",
    "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
    "\n",
    "def compute_student_loss(images, labels):\n",
    "    \"\"\"Compute class knowledge distillation student loss for given images\n",
    "     and labels.\n",
    "\n",
    "    Args:\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "\n",
    "    Returns:\n",
    "    Scalar loss Tensor.\n",
    "    \"\"\"\n",
    "    student_class_logits = fc_model(images, training=True)\n",
    "\n",
    "    # Compute class distillation loss between student class logits and\n",
    "    # softened teacher class targets probabilities.\n",
    "\n",
    "    # your code start from here for step 3\n",
    "\n",
    "    teacher_class_logits = cnn_model(images, training=False)\n",
    "    distillation_loss_value = distillation_loss(teacher_class_logits, student_class_logits, DISTILLATION_TEMPERATURE)\n",
    "\n",
    "    # Compute cross-entropy loss with hard targets.\n",
    "\n",
    "    # your code start from here for step 3\n",
    "    \n",
    "    cross_entropy_loss_value = tf.keras.losses.categorical_crossentropy(labels, tf.nn.softmax(student_class_logits))\n",
    "\n",
    "    total_loss = ALPHA * cross_entropy_loss_value + (1 - ALPHA) * distillation_loss_value\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJ1uyvurQ3w4",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Train and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EtoLbp8uQ4Vl"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "    def compute_num_correct(model, images, labels):\n",
    "    \"\"\"Compute number of correctly classified images in a batch.\n",
    "\n",
    "    Args:\n",
    "    model: Instance of tf.keras.Model.\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "\n",
    "    Returns:\n",
    "    Number of correctly classified images.\n",
    "    \"\"\"\n",
    "    class_logits = model(images, training=False)\n",
    "    return tf.reduce_sum(\n",
    "        tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),\n",
    "              tf.float32)), tf.argmax(class_logits, -1), tf.argmax(labels, -1)\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, compute_loss_fn, num_epochs, learning_rate):\n",
    "    \"\"\"Perform training and evaluation for a given model.\n",
    "\n",
    "    Args:\n",
    "    model: Instance of tf.keras.Model.\n",
    "    compute_loss_fn: A function that computes the training loss given the\n",
    "        images, and labels.\n",
    "    num_epochs: Number of epochs to train for\n",
    "    learning_rate: Optimizer learning rate\n",
    "    \"\"\"\n",
    "\n",
    "    # your code start from here for step 4\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "    # Run training.\n",
    "    print('Epoch {}: '.format(epoch), end='')\n",
    "    for images, labels in mhist_train:\n",
    "        with tf.GradientTape() as tape:\n",
    "             # your code start from here for step 4\n",
    "\n",
    "            loss_value = compute_loss_fn(images, labels)\n",
    "\n",
    "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # Run evaluation.\n",
    "    num_correct = 0\n",
    "    num_total = builder.info.splits['test'].num_examples\n",
    "    for images, labels in mnist_test:\n",
    "        # your code start from here for step 4\n",
    "        num_correct += compute_num_correct(model,images,labels)[0]\n",
    "    print(\"Class_accuracy: \" + '{:.2f}%'.format(num_correct / num_total * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQL1lJdaRPT1"
   },
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-AGHbyABRPz3"
   },
   "outputs": [],
   "source": [
    "# your code start from here for step 5 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sj1N38fnRTNB"
   },
   "source": [
    "# Test accuracy vs. tempreture curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gX4dbazrRWIz"
   },
   "outputs": [],
   "source": [
    "# your code start from here for step 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNrH_1emRbGA"
   },
   "source": [
    "# Train student from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjospsxIRbQ6"
   },
   "outputs": [],
   "source": [
    "# Build fully connected student.\n",
    "fc_model_no_distillation = tf.keras.Sequential()\n",
    "\n",
    "# your code start from here for step 7\n",
    "\n",
    "\n",
    "\n",
    "#@test {\"output\": \"ignore\"}\n",
    "\n",
    "def compute_plain_cross_entropy_loss(images, labels):\n",
    "  \"\"\"Compute plain loss for given images and labels.\n",
    "\n",
    "  For fair comparison and convenience, this function also performs a\n",
    "  LogSumExp over classes, but does not perform class distillation.\n",
    "\n",
    "  Args:\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "\n",
    "  Returns:\n",
    "    Scalar loss Tensor.\n",
    "  \"\"\"\n",
    "  # your code start from here for step 7\n",
    "\n",
    "  student_class_logits = fc_model_no_distillation(images, training=True)\n",
    "  cross_entropy_loss = \n",
    "  \n",
    "  return cross_entropy_loss\n",
    "\n",
    "\n",
    "train_and_evaluate(fc_model_no_distillation, compute_plain_cross_entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq3JTpQ4RuhR"
   },
   "source": [
    "# Comparing the teacher and student model (number of of parameters and FLOPs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4V8GB2yRRuxF"
   },
   "outputs": [],
   "source": [
    "# your code start from here for step 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b5yNhJfRu-7"
   },
   "source": [
    "# XAI method to explain models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yFgp5kA5RvID"
   },
   "outputs": [],
   "source": [
    "# your code start from here for step 9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjwJ5oziRvRn"
   },
   "source": [
    "# Implementing the state-of-the-art KD algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q10lybAFRvZt"
   },
   "outputs": [],
   "source": [
    "# your code start from here for step 13\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Task1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
