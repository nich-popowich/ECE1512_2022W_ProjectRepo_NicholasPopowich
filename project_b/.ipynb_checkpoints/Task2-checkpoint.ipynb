{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WYMfvCNPwpm"
   },
   "source": [
    "# Project B: Knowledge Distillation for Building Lightweight Deep Learning Models in Visual Classification Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vA8ppgB2P0aJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTRAIN_BATCHES = 4\\nTEST_BATCHES = 4\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from typing import Union\n",
    "\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "# Not originally included\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "NUM_INIT_EPOCHS = 10\n",
    "NUM_FINE_EPOCHS = 25\n",
    "\n",
    "ENTROPY_ZERO_FILLER = 1e-15\n",
    "NUM_CLASSES = 2 #SSA or HP\n",
    "TRAIN_BATCHES = int(np.floor(2176/BATCH_SIZE))\n",
    "TEST_BATCHES = int(np.floor(976/BATCH_SIZE))\n",
    "\n",
    "# For quick testing purposes ONLY\n",
    "\"\"\"\n",
    "TRAIN_BATCHES = 4\n",
    "TEST_BATCHES = 4\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2EFLQROP2R7"
   },
   "source": [
    "## Data loading/augmenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2176 images belonging to 2 classes.\n",
      "Found 2176 images belonging to 2 classes.\n",
      "Found 976 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Adapted from Project A's HMT Dataset loading code to use the ImageDataGenerator to augment the data and preload labels/image batches\n",
    "\n",
    "img_dir = 'mhist_dataset/images'\n",
    "train_dir = 'mhist_dataset/images/train'\n",
    "test_dir = 'mhist_dataset/images/test'\n",
    "anno_csv = 'mhist_dataset/annotations.csv'\n",
    "\n",
    "\n",
    "if not os.path.isdir(train_dir):\n",
    "    os.mkdir(train_dir)\n",
    "if not os.path.isdir(test_dir):\n",
    "    os.mkdir(test_dir)\n",
    "    \n",
    "if not os.path.isdir(os.path.join(train_dir, '01_HP')):\n",
    "    os.mkdir(os.path.join(train_dir, '01_HP'))\n",
    "if not os.path.isdir(os.path.join(train_dir, '02_SSA')):\n",
    "    os.mkdir(os.path.join(train_dir, '02_SSA'))\n",
    "if not os.path.isdir(os.path.join(test_dir, '01_HP')):\n",
    "    os.mkdir(os.path.join(test_dir, '01_HP'))\n",
    "if not os.path.isdir(os.path.join(test_dir, '02_SSA')):\n",
    "    os.mkdir(os.path.join(test_dir, '02_SSA'))\n",
    "    \n",
    "# load csv\n",
    "# label struct: [HP, SSA]\n",
    "# labels as a list are sorted in alphabetical order as per the csv\n",
    "\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "train_img = []\n",
    "test_img = []\n",
    "\n",
    "with open(anno_csv, 'r') as csvfile:\n",
    "    first_row = True\n",
    "    for row in csv.reader(csvfile):\n",
    "        if first_row:\n",
    "            first_row = False\n",
    "            continue\n",
    "        if row[3] == 'train':\n",
    "            train_img.append(row[0])\n",
    "            if row[1] == 'HP':\n",
    "                train_labels.append([1, 0])\n",
    "            elif row[1] == 'SSA':\n",
    "                train_labels.append([0, 1])\n",
    "        elif row[3] == 'test':\n",
    "            test_img.append(row[0])\n",
    "            if row[1] == 'HP':\n",
    "                test_labels.append([1, 0])\n",
    "            elif row[1] == 'SSA':\n",
    "                test_labels.append([0, 1])\n",
    "        if row[0] in os.listdir(img_dir):\n",
    "            if row[1] == 'HP' and row[3] == 'train':\n",
    "                os.rename(os.path.join(img_dir, row[0]), os.path.join(train_dir, '01_HP', row[0]))\n",
    "            elif row[1] == 'SSA' and row[3] == 'train':\n",
    "                os.rename(os.path.join(img_dir, row[0]), os.path.join(train_dir, '02_SSA', row[0]))\n",
    "            elif row[1] == 'HP' and row[3] == 'test':\n",
    "                os.rename(os.path.join(img_dir, row[0]), os.path.join(test_dir, '01_HP', row[0]))\n",
    "            elif row[1] == 'SSA' and row[3] == 'test':\n",
    "                os.rename(os.path.join(img_dir, row[0]), os.path.join(test_dir, '02_SSA', row[0]))\n",
    "    \n",
    "# Data Augmentation using ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.,\n",
    "shear_range=0.1,\n",
    "rotation_range=15,\n",
    "horizontal_flip=True,\n",
    "vertical_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "class_mode='categorical',\n",
    "interpolation='bilinear',\n",
    "target_size=(224, 224),\n",
    "batch_size=BATCH_SIZE,\n",
    "shuffle=True) # 68 batches of 32\n",
    "\n",
    "t2_generator = test_datagen.flow_from_directory(train_dir,\n",
    "class_mode='categorical',\n",
    "interpolation='bilinear',\n",
    "target_size=(224, 224),\n",
    "batch_size=BATCH_SIZE,\n",
    "shuffle=True) # 68 batches of 32\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "class_mode='categorical',\n",
    "interpolation='bilinear',\n",
    "target_size=(224, 224),\n",
    "batch_size=BATCH_SIZE,\n",
    "shuffle=False) # 30.5 batches of 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAZwfvW5P63q",
    "tags": []
   },
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zINgDkA7P7BP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 1000)              25613800  \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 2002      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,615,802\n",
      "Trainable params: 25,570,362\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 1000)             3538984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 2)                 2002      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,540,986\n",
      "Trainable params: 3,506,874\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 1000)             3538984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 2)                 2002      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,540,986\n",
      "Trainable params: 3,506,874\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#@test {\"output\": \"ignore\"}\n",
    "# citing https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet50V2, https://www.kaggle.com/code/suniliitb96/tutorial-keras-transfer-learning-with-resnet50/notebook,\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v2/MobileNetV2 and https://github.com/Abhi-T/MNIST-CLASSIFIER-From-Scratch/blob/main/MNIST__handwritten_digit_Model.ipynb\n",
    "\n",
    "# Build CNN teacher.\n",
    "\n",
    "teacher_model = tf.keras.Sequential()\n",
    "\n",
    "# your code start from here for step 2\n",
    "\n",
    "teacher_model.add(tf.keras.applications.resnet_v2.ResNet50V2(classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "teacher_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(teacher_model.summary())\n",
    "\n",
    "# Build fully connected students\n",
    "student_kd_model = tf.keras.Sequential()\n",
    "student_kd_model.add(tf.keras.applications.mobilenet_v2.MobileNetV2(classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "student_kd_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(student_kd_model.summary())\n",
    "\n",
    "student_scratch_model = tf.keras.Sequential()\n",
    "student_scratch_model.add(tf.keras.applications.mobilenet_v2.MobileNetV2(classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "student_scratch_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(student_scratch_model.summary())\n",
    "\n",
    "\n",
    "# your code start from here for step 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JWGucyrQGav",
    "tags": []
   },
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DhzBP6ZLQJ57"
   },
   "outputs": [],
   "source": [
    "def compute_teacher_loss(model, images, labels, **kwargs):\n",
    "    \"\"\"Compute class knowledge distillation teacher loss for given images\n",
    "     and labels.\n",
    "\n",
    "    Args:\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "    kwargs: n/a\n",
    "\n",
    "    Returns:\n",
    "    Scalar loss Tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    class_logits = model(images, training=True)\n",
    "\n",
    "    # Compute cross-entropy loss for classes.\n",
    "    \n",
    "    cross_entropy_loss_value = tf.nn.softmax_cross_entropy_with_logits(labels, class_logits)\n",
    "\n",
    "    return cross_entropy_loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JS8xkuH0QbOS",
    "tags": []
   },
   "source": [
    "## Student (KD) Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lDKia4gPQMIr"
   },
   "outputs": [],
   "source": [
    "# adapted from https://keras.io/examples/vision/knowledge_distillation/\n",
    "\n",
    "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
    "                      temperature: Union[float, tf.Tensor]):\n",
    "    \"\"\"Compute distillation loss.\n",
    "\n",
    "    This function computes cross entropy between softened logits and softened\n",
    "    targets. The resulting loss is scaled by the squared temperature so that\n",
    "    the gradient magnitude remains approximately constant as the temperature is\n",
    "    changed. For reference, see Hinton et al., 2014, \"Distilling the knowledge in\n",
    "    a neural network.\"\n",
    "\n",
    "    Args:\n",
    "    teacher_logits: A Tensor of logits provided by the teacher.\n",
    "    student_logits: A Tensor of logits provided by the student, of the same\n",
    "      shape as `teacher_logits`.\n",
    "    temperature: Temperature to use for distillation.\n",
    "\n",
    "    Returns:\n",
    "    A scalar Tensor containing the distillation loss.\n",
    "    \"\"\"\n",
    "    # your code start from here for step 3\n",
    "    soft_targets = teacher_logits / temperature\n",
    "\n",
    "    return tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(\n",
    "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
    "\n",
    "def compute_student_loss(student_model, images, labels, **kwargs):\n",
    "    \"\"\"Compute class knowledge distillation student loss for given images\n",
    "     and labels.\n",
    "\n",
    "    Args:\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "    kwargs:\n",
    "        teacher_model: Teacher model\n",
    "        temperature: Temperature hyperparameter\n",
    "        alpha: Alpha hyperparameter\n",
    "\n",
    "    Returns:\n",
    "    Scalar loss Tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    teacher_model = kwargs['teacher_model']\n",
    "    temperature = kwargs['temperature']\n",
    "    alpha = kwargs['alpha']\n",
    "    \n",
    "    student_class_logits = student_model(images, training=True)\n",
    "\n",
    "    # Compute class distillation loss between student class logits and\n",
    "    # softened teacher class targets probabilities.\n",
    "\n",
    "    teacher_class_logits = teacher_model(images, training=False)\n",
    "    distillation_loss_value = distillation_loss(teacher_class_logits, student_class_logits, temperature)\n",
    "\n",
    "    # Compute cross-entropy loss with hard targets.\n",
    "    \n",
    "    cross_entropy_loss_value = tf.nn.softmax_cross_entropy_with_logits(labels, student_class_logits)\n",
    "\n",
    "    total_loss = alpha * cross_entropy_loss_value + (1 - alpha) * distillation_loss_value\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student (Scratch) Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_student_scratch_loss(model, images, labels, **kwargs):\n",
    "    \"\"\"Compute class student (scratch) loss for given images\n",
    "     and labels.\n",
    "\n",
    "    Args:\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "    kwargs:\n",
    "        temperature: Temperature hyperparameter\n",
    "\n",
    "    Returns:\n",
    "    Scalar loss Tensor.\n",
    "    \"\"\"\n",
    "    temperature = kwargs['temperature']\n",
    "    \n",
    "    class_logits = model(images, training=True)\n",
    "\n",
    "    # Compute cross-entropy loss for classes.\n",
    "    \n",
    "    cross_entropy_loss_value = tf.nn.softmax_cross_entropy_with_logits(labels, class_logits/temperature) * temperature ** 2\n",
    "\n",
    "    return cross_entropy_loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJ1uyvurQ3w4",
    "tags": []
   },
   "source": [
    "# Train and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EtoLbp8uQ4Vl"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_num_correct(model, images, labels):\n",
    "    \"\"\"Compute number of correctly classified images in a batch.\n",
    "\n",
    "    Args:\n",
    "    model: Instance of tf.keras.Model.\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "\n",
    "    Returns:\n",
    "    Number of correctly classified images.\n",
    "    \"\"\"\n",
    "    class_logits = model(images, training=False)\n",
    "    return tf.reduce_sum(\n",
    "        tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),\n",
    "              tf.float32)), tf.argmax(class_logits, -1), tf.argmax(labels, -1)\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, compute_loss_fn, num_epochs, learning_rate, **kwargs):\n",
    "    \"\"\"Perform training and evaluation for a given model.\n",
    "\n",
    "    Args:\n",
    "    model: Main Instance of tf.keras.Model.\n",
    "    compute_loss_fn: A function that computes the training loss given the\n",
    "        images, and labels.\n",
    "    num_epochs: Number of epochs to train for\n",
    "    learning_rate: Optimizer learning rate\n",
    "    kwargs: Passed through to loss fn\n",
    "    \"\"\"\n",
    "\n",
    "    # your code start from here for step 4\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    train_generator.reset()\n",
    "    \n",
    "    accuracy = 0\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Run training.\n",
    "        print('Epoch {}: '.format(epoch), end='')\n",
    "\n",
    "        #for images, labels in mhist_train:\n",
    "        for batch in range(TRAIN_BATCHES):\n",
    "            \n",
    "            images, labels = train_generator.next()\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "\n",
    "                loss_value = compute_loss_fn(model, images, labels, **kwargs)\n",
    "\n",
    "            grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        # Run evaluation.\n",
    "        num_correct = 0\n",
    "        num_total = BATCH_SIZE*TEST_BATCHES\n",
    "        \n",
    "        test_generator.reset()\n",
    "        \n",
    "        for batch in range(TEST_BATCHES):\n",
    "            images, labels = test_generator.next()\n",
    "            num_correct += compute_num_correct(model,images,labels)[0]\n",
    "        accuracy = num_correct / num_total * 100\n",
    "        print(\"Class_accuracy: \" + '{:.2f}%'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQL1lJdaRPT1"
   },
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-AGHbyABRPz3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Run: Initial\n",
      "Epoch 1: Class_accuracy: 75.00%\n",
      "Epoch 2: Class_accuracy: 80.02%\n",
      "Epoch 3: Class_accuracy: 75.61%\n",
      "Epoch 4: Class_accuracy: 73.98%\n",
      "Epoch 5: Class_accuracy: 58.61%\n",
      "Epoch 6: Class_accuracy: 77.66%\n",
      "Epoch 7: Class_accuracy: 65.68%\n",
      "Epoch 8: Class_accuracy: 78.07%\n",
      "Epoch 9: Class_accuracy: 65.57%\n",
      "Epoch 10: Class_accuracy: 79.82%\n",
      "\n",
      "Teacher Run: Fine\n",
      "Epoch 1: Class_accuracy: 80.43%\n",
      "Epoch 2: Class_accuracy: 80.23%\n",
      "Epoch 3: Class_accuracy: 82.58%\n",
      "Epoch 4: Class_accuracy: 81.25%\n",
      "Epoch 5: Class_accuracy: 81.25%\n",
      "Epoch 6: Class_accuracy: 84.12%\n",
      "Epoch 7: Class_accuracy: 84.12%\n",
      "Epoch 8: Class_accuracy: 83.91%\n",
      "Epoch 9: Class_accuracy: 84.94%\n",
      "Epoch 10: Class_accuracy: 83.61%\n",
      "Epoch 11: Class_accuracy: 82.68%\n",
      "Epoch 12: Class_accuracy: 84.63%\n",
      "Epoch 13: Class_accuracy: 82.89%\n",
      "Epoch 14: Class_accuracy: 84.12%\n",
      "Epoch 15: Class_accuracy: 81.86%\n",
      "Epoch 16: Class_accuracy: 85.14%\n",
      "Epoch 17: Class_accuracy: 85.66%\n",
      "Epoch 18: Class_accuracy: 85.35%\n",
      "Epoch 19: Class_accuracy: 85.55%\n",
      "Epoch 20: Class_accuracy: 84.43%\n",
      "Epoch 21: Class_accuracy: 84.43%\n",
      "Epoch 22: Class_accuracy: 85.35%\n",
      "Epoch 23: Class_accuracy: 86.37%\n",
      "Epoch 24: Class_accuracy: 84.12%\n",
      "Epoch 25: Class_accuracy: 83.81%\n",
      "\n",
      "\n",
      "Student (KD) Run: Initial\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 36.78%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 36.78%\n",
      "Epoch 7: Class_accuracy: 36.78%\n",
      "Epoch 8: Class_accuracy: 36.78%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "\n",
      "Student (KD) Run: Fine\n",
      "Epoch 1: Class_accuracy: 36.78%\n",
      "Epoch 2: Class_accuracy: 37.19%\n",
      "Epoch 3: Class_accuracy: 36.78%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 36.78%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "Epoch 11: Class_accuracy: 63.22%\n",
      "Epoch 12: Class_accuracy: 63.22%\n",
      "Epoch 13: Class_accuracy: 63.22%\n",
      "Epoch 14: Class_accuracy: 63.22%\n",
      "Epoch 15: Class_accuracy: 63.22%\n",
      "Epoch 16: Class_accuracy: 36.78%\n",
      "Epoch 17: Class_accuracy: 63.22%\n",
      "Epoch 18: Class_accuracy: 63.22%\n",
      "Epoch 19: Class_accuracy: 63.22%\n",
      "Epoch 20: Class_accuracy: 36.78%\n",
      "Epoch 21: Class_accuracy: 63.22%\n",
      "Epoch 22: Class_accuracy: 36.68%\n",
      "Epoch 23: Class_accuracy: 63.22%\n",
      "Epoch 24: Class_accuracy: 63.22%\n",
      "Epoch 25: Class_accuracy: 63.22%\n",
      "\n",
      "\n",
      "Student (Scratch) Run: Initial\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.63%\n",
      "Epoch 4: Class_accuracy: 42.01%\n",
      "Epoch 5: Class_accuracy: 48.16%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 40.27%\n",
      "Epoch 8: Class_accuracy: 43.75%\n",
      "Epoch 9: Class_accuracy: 36.78%\n",
      "Epoch 10: Class_accuracy: 46.00%\n",
      "\n",
      "Student (Scratch) Run: Fine\n",
      "Epoch 1: Class_accuracy: 62.70%\n",
      "Epoch 2: Class_accuracy: 64.04%\n",
      "Epoch 3: Class_accuracy: 64.04%\n",
      "Epoch 4: Class_accuracy: 63.83%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 64.34%\n",
      "Epoch 7: Class_accuracy: 63.63%\n",
      "Epoch 8: Class_accuracy: 63.32%\n",
      "Epoch 9: Class_accuracy: 65.27%\n",
      "Epoch 10: Class_accuracy: 63.93%\n",
      "Epoch 11: Class_accuracy: 64.75%\n",
      "Epoch 12: Class_accuracy: 63.93%\n",
      "Epoch 13: Class_accuracy: 69.57%\n",
      "Epoch 14: Class_accuracy: 70.08%\n",
      "Epoch 15: Class_accuracy: 63.83%\n",
      "Epoch 16: Class_accuracy: 63.42%\n",
      "Epoch 17: Class_accuracy: 63.32%\n",
      "Epoch 18: Class_accuracy: 68.65%\n",
      "Epoch 19: Class_accuracy: 66.80%\n",
      "Epoch 20: Class_accuracy: 67.73%\n",
      "Epoch 21: Class_accuracy: 65.37%\n",
      "Epoch 22: Class_accuracy: 69.06%\n",
      "Epoch 23: Class_accuracy: 67.93%\n",
      "Epoch 24: Class_accuracy: 73.67%\n",
      "Epoch 25: Class_accuracy: 66.70%\n"
     ]
    }
   ],
   "source": [
    "# your code start from here for step 5 \n",
    "\n",
    "print(\"Teacher Run: Initial\")\n",
    "train_and_evaluate(teacher_model, compute_teacher_loss, NUM_INIT_EPOCHS, 1e-4)\n",
    "print(\"\\nTeacher Run: Fine\")\n",
    "teach_acc = train_and_evaluate(teacher_model, compute_teacher_loss, NUM_FINE_EPOCHS, 1e-5)\n",
    "\n",
    "print(\"\\n\\nStudent (KD) Run: Initial\")\n",
    "train_and_evaluate(student_kd_model, compute_student_loss, NUM_INIT_EPOCHS, 1e-3, teacher_model=teacher_model, temperature=4, alpha=0.5)\n",
    "print(\"\\nStudent (KD) Run: Fine\")\n",
    "skd_acc = train_and_evaluate(student_kd_model, compute_student_loss, NUM_FINE_EPOCHS, 1e-4, teacher_model=teacher_model, temperature=4, alpha=0.5)\n",
    "\n",
    "print(\"\\n\\nStudent (Scratch) Run: Initial\")\n",
    "train_and_evaluate(student_scratch_model, compute_student_scratch_loss, NUM_INIT_EPOCHS, 1e-3, temperature=4)\n",
    "print(\"\\nStudent (Scratch) Run: Fine\")\n",
    "ss_acc = train_and_evaluate(student_scratch_model, compute_student_scratch_loss, NUM_FINE_EPOCHS, 1e-4, temperature=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sj1N38fnRTNB"
   },
   "source": [
    "# Test Accuracy vs. Temperature Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gX4dbazrRWIz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Student (KD, Temperature = 1) Run: Initial\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 63.22%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "\n",
      "Student (KD, Temperature = 1) Run: Fine\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 63.22%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "Epoch 11: Class_accuracy: 63.22%\n",
      "Epoch 12: Class_accuracy: 63.22%\n",
      "Epoch 13: Class_accuracy: 63.22%\n",
      "Epoch 14: Class_accuracy: 63.22%\n",
      "Epoch 15: Class_accuracy: 63.22%\n",
      "Epoch 16: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m train_and_evaluate(student_dict[temp], compute_student_loss, NUM_INIT_EPOCHS, \u001b[38;5;241m1e-3\u001b[39m, teacher_model\u001b[38;5;241m=\u001b[39mteacher_model, temperature\u001b[38;5;241m=\u001b[39mtemp, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStudent (KD, Temperature = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) Run: Fine\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m acc_dict[temp] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_student_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_FINE_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mteacher_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, compute_loss_fn, num_epochs, learning_rate, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m#for images, labels in mhist_train:\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(TRAIN_BATCHES):\n\u001b[1;32m---> 45\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m     49\u001b[0m         loss_value \u001b[38;5;241m=\u001b[39m compute_loss_fn(model, images, labels, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\users\\nich_\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py:116\u001b[0m, in \u001b[0;36mIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m     index_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_generator)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# so it can be done in parallel\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_batches_of_transformed_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\nich_\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py:227\u001b[0m, in \u001b[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    225\u001b[0m filepaths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepaths\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(index_array):\n\u001b[1;32m--> 227\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepaths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m                   \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     x \u001b[38;5;241m=\u001b[39m img_to_array(img, data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format)\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;66;03m# Pillow images should be closed after `load_img`,\u001b[39;00m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;66;03m# but not PIL images.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\nich_\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:139\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    137\u001b[0m         resample \u001b[38;5;241m=\u001b[39m _PIL_INTERPOLATION_METHODS[interpolation]\n\u001b[0;32m    138\u001b[0m         img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize(width_height_tuple, resample)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Original student uses temperature 4\n",
    "student_kd_model1 = tf.keras.Sequential()\n",
    "student_kd_model1.add(tf.keras.applications.mobilenet_v2.MobileNetV2(classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "student_kd_model1.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "\n",
    "student_kd_model2 = tf.keras.Sequential()\n",
    "student_kd_model2.add(tf.keras.applications.mobilenet_v2.MobileNetV2(classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "student_kd_model2.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "\n",
    "student_kd_model16 = tf.keras.Sequential()\n",
    "student_kd_model16.add(tf.keras.applications.mobilenet_v2.MobileNetV2(classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "student_kd_model16.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "\n",
    "student_kd_model32 = tf.keras.Sequential()\n",
    "student_kd_model32.add(tf.keras.applications.mobilenet_v2.MobileNetV2(classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "student_kd_model32.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "\n",
    "student_kd_model64 = tf.keras.Sequential()\n",
    "student_kd_model64.add(tf.keras.applications.mobilenet_v2.MobileNetV2(classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "student_kd_model64.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "\n",
    "student_dict = {1: student_kd_model1, 2: student_kd_model2, 4: student_kd_model, 16: student_kd_model16, 32: student_kd_model32, 64: student_kd_model64}\n",
    "acc_dict = {4: 63.32}\n",
    "\n",
    "for temp in [1, 2, 16, 32, 64]:\n",
    "    print(f'Student (KD, Temperature = {temp}) Run: Initial')\n",
    "    train_and_evaluate(student_dict[temp], compute_student_loss, NUM_INIT_EPOCHS, 1e-3, teacher_model=teacher_model, temperature=temp, alpha=0.5)\n",
    "    print(f'\\nStudent (KD, Temperature = {temp}) Run: Fine')\n",
    "    acc_dict[temp] = train_and_evaluate(student_dict[temp], compute_student_loss, NUM_FINE_EPOCHS, 1e-4, teacher_model=teacher_model, temperature=temp, alpha=0.5)\n",
    "    print('\\n')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels.h5\n",
      "242753536/242745792 [==============================] - 3s 0us/step\n",
      "242761728/242745792 [==============================] - 3s 0us/step\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 1000)              25613800  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 2002      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,615,802\n",
      "Trainable params: 25,570,362\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 1000)              25613800  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 2002      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,615,802\n",
      "Trainable params: 25,570,362\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'student_takd_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m takd_student_takd_model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mapplications\u001b[38;5;241m.\u001b[39mmobilenet_v2\u001b[38;5;241m.\u001b[39mMobileNetV2(classifier_activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m)))\n\u001b[0;32m     13\u001b[0m takd_student_takd_model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(NUM_CLASSES)) \n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mstudent_takd_model\u001b[49m\u001b[38;5;241m.\u001b[39msummary())\n\u001b[0;32m     16\u001b[0m takd_student_teacherkd_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[0;32m     17\u001b[0m takd_student_teacherkd_model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mapplications\u001b[38;5;241m.\u001b[39mmobilenet_v2\u001b[38;5;241m.\u001b[39mMobileNetV2(classifier_activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, input_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'student_takd_model' is not defined"
     ]
    }
   ],
   "source": [
    "takd_teacher_model = tf.keras.Sequential()\n",
    "takd_teacher_model.add(tf.keras.applications.resnet_v2.ResNet152V2(classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "takd_teacher_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(teacher_model.summary())\n",
    "\n",
    "takd_ta_model = tf.keras.Sequential()\n",
    "takd_ta_model.add(tf.keras.applications.resnet_v2.ResNet50V2(classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "takd_ta_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(teacher_model.summary())\n",
    "\n",
    "takd_student_takd_model = tf.keras.Sequential()\n",
    "takd_student_takd_model.add(tf.keras.applications.mobilenet_v2.MobileNetV2(classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "takd_student_takd_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(student_takd_model.summary())\n",
    "\n",
    "takd_student_teacherkd_model = tf.keras.Sequential()\n",
    "takd_student_teacherkd_model.add(tf.keras.applications.mobilenet_v2.MobileNetV2(classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "takd_student_teacherkd_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(student_teacherkd_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TAKD Teacher Run: Initial\")\n",
    "train_and_evaluate(takd_teacher_model, compute_teacher_loss, NUM_INIT_EPOCHS, 1e-4)\n",
    "print(\"\\nTAKD Teacher Run: Fine\")\n",
    "takd_teach_acc = train_and_evaluate(takd_teacher_model, compute_teacher_loss, NUM_FINE_EPOCHS, 1e-5)\n",
    "\n",
    "print(\"\\n\\TAKD TA Run: Initial\")\n",
    "train_and_evaluate(takd_ta_model, compute_student_loss, NUM_INIT_EPOCHS, 1e-3, teacher_model=takd_teacher_model, temperature=4, alpha=0.5)\n",
    "print(\"\\nTAKD TA Run: Fine\")\n",
    "takd_ta_acc = train_and_evaluate(takd_ta_model, compute_student_loss, NUM_FINE_EPOCHS, 1e-4, teacher_model=takd_teacher_model, temperature=4, alpha=0.5)\n",
    "\n",
    "print(\"\\n\\nTAKD Student (TA Distilled) Run: Initial\")\n",
    "train_and_evaluate(takd_student_takd_model, compute_student_loss, NUM_INIT_EPOCHS, 1e-3, teacher_model=takd_ta_model, temperature=4, alpha=0.5)\n",
    "print(\"\\nTAKD Student (TA Distilled) Run: Fine\")\n",
    "takd_stakd_acc = train_and_evaluate(takd_student_takd_model, compute_student_loss, NUM_FINE_EPOCHS, 1e-4, teacher_model=takd_ta_model, temperature=4, alpha=0.5)\n",
    "\n",
    "print(\"\\n\\nTAKD Student (Teacher Distilled) Run: Initial\")\n",
    "train_and_evaluate(takd_student_teacherkd_model, compute_student_loss, NUM_INIT_EPOCHS, 1e-3, teacher_model=takd_teacher_model, temperature=4, alpha=0.5)\n",
    "print(\"\\nTAKD Student (Teacher Distilled) Run: Fine\")\n",
    "takd_steachkd_acc = train_and_evaluate(takd_student_teacherkd_model, compute_student_loss, NUM_FINE_EPOCHS, 1e-4, teacher_model=takd_teacher_model, temperature=4, alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNrH_1emRbGA"
   },
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model.save('teacher.h5')\n",
    "student_kd_model.save('student_kd4.h5')\n",
    "student_scratch_model.save('student_scratch.h5')\n",
    "student_kd_model1.save('student_kd1.h5')\n",
    "student_kd_model2.save('student_kd2.h5')\n",
    "student_kd_model16.save('student_kd16.h5')\n",
    "student_kd_model32.save('student_kd32.h5')\n",
    "student_kd_model64.save('student_kd64.h5')\n",
    "takd_teacher_model.save('takd_teacher.h5')\n",
    "takd_ta_model.save('takd_ta.h5')\n",
    "takd_student_takd_model.save('takd_student_takd.h5')\n",
    "takd_student_teacherkd_model.save('takd_student_teacherkd.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq3JTpQ4RuhR"
   },
   "source": [
    "# Comparing the teacher and student model (number of of parameters and FLOPs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4V8GB2yRRuxF"
   },
   "outputs": [],
   "source": [
    "# your code start from here for step 8\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Task1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
