{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task1 (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project B: Knowledge Distillation for Building Lightweight Deep Learning Models in Visual Classification Tasks"
      ],
      "metadata": {
        "id": "6WYMfvCNPwpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from typing import Union\n",
        "\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "builder = tfds.builder('mnist')\n",
        "BATCH_SIZE = 256\n",
        "NUM_EPOCHS = 12\n",
        "NUM_CLASSES = 10  # 10 total classes."
      ],
      "metadata": {
        "id": "vA8ppgB2P0aJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "#from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "6gnTDdemHLV0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loading"
      ],
      "metadata": {
        "id": "H2EFLQROP2R7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train and test splits.\n",
        "def preprocess(x):\n",
        "  image = tf.image.convert_image_dtype(x['image'], tf.float32)\n",
        "  class_labels = tf.one_hot(x['label'], builder.info.features['label'].num_classes)\n",
        "  return image, class_labels\n",
        "\n",
        "\n",
        "mnist_train = tfds.load('mnist', split='train', shuffle_files=False).cache()\n",
        "mnist_train = mnist_train.map(preprocess)\n",
        "mnist_train = mnist_train.shuffle(builder.info.splits['train'].num_examples)\n",
        "mnist_train = mnist_train.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "mnist_test = tfds.load('mnist', split='test').cache()\n",
        "mnist_test = mnist_test.map(preprocess).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "ynByMG_UP4A4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yV3LZSMfTtn",
        "outputId": "bd78417c-49c2-4f1e-e8ff-3c7786841553"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(256, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model creation"
      ],
      "metadata": {
        "id": "kAZwfvW5P63q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Build CNN teacher.\n",
        "#cnn_model = tf.keras.Sequential()\n",
        "\n",
        "# your code start from here for stpe 2\n",
        "teacher = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\"),\n",
        "        #layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        #layers.Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dropout(0.5),\n",
        "        #layers.Dense(10),\n",
        "        #layers.Dense(10, activation=\"softmax\")\n",
        "        layers.Dense(10)\n",
        "    ],\n",
        "    name=\"teacher\",\n",
        ")\n",
        "\n",
        "\n",
        "# Build fully connected student.\n",
        "#fc_model = tf.keras.Sequential()\n",
        "\n",
        "\n",
        "# your code start from here for step 2\n",
        "\n",
        "student = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(784, activation=\"relu\"),\n",
        "        layers.Dense(784, activation=\"relu\"),\n",
        "        #layers.Dense(10),\n",
        "        #layers.Dense(10, activation=\"softmax\")\n",
        "        layers.Dense(10)\n",
        "        # model.add(Activation('relu'))\n",
        "    ],\n",
        "    name=\"student\",\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zINgDkA7P7BP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Xr_zY1WwCqpj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NLovqeysCqua"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher.fit(mnist_train, epochs=5)\n"
      ],
      "metadata": {
        "id": "zqdH3hz_Dm52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HnQNSu3P3Pb",
        "outputId": "53bcfd17-4adb-4d65-f22c-4cdeeb822d09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"student\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 784)               615440    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 784)               615440    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                7850      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,238,730\n",
            "Trainable params: 1,238,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT4RNtGkCvDY",
        "outputId": "ea36ece7-8a34-4470-93f0-1a8d32d3ffae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"teacher\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 28, 28, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1605760   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,625,866\n",
            "Trainable params: 1,625,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFfPuzb5J0Vu",
        "outputId": "006d558f-ab54-4116-8bb1-2e748147f4f6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(256, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the teacher model\n",
        "teacher.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), metrics=[\"accuracy\"])\n"
      ],
      "metadata": {
        "id": "N3bzIjUUt94h"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher.fit(mnist_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "1ppTDqa_uA0o",
        "outputId": "675a32a3-aabe-4bd0-9a15-7781f072c1c9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            " 66/234 [=======>......................] - ETA: 2:30 - loss: 2.2645 - accuracy: 0.1533"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-983f715aed66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher2 = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\"),\n",
        "        #layers.Conv2D(256, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\"),\n",
        "        #layers.Conv2D(512, (3, 3), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(128, activation=\"relu\"),\n",
        "        layers.Dropout(0.5),\n",
        "        #layers.Dense(10),\n",
        "        #layers.Dense(10, activation=\"softmax\")\n",
        "        layers.Dense(10)\n",
        "    ],\n",
        "    name=\"teacher2\",\n",
        ")"
      ],
      "metadata": {
        "id": "CfKu_WcK4SY0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unpack data"
      ],
      "metadata": {
        "id": "6yySUuI2Nno_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_example, =mnist_train.take(1)\n",
        "image, label = mnist_example\n"
      ],
      "metadata": {
        "id": "6aScN7bZ5pP6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teacher loss function"
      ],
      "metadata": {
        "id": "8JWGucyrQGav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def compute_teacher_loss(images, labels):\n",
        "  \"\"\"Compute class knowledge distillation teacher loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  class_logits = teacher2(images, training=True)\n",
        "\n",
        "  # Compute cross-entropy loss for classes.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "  cross_entropy_loss_value =tf.reduce_mean(tf.keras.losses.categorical_crossentropy(labels, class_logits, from_logits=True))\n",
        "\n",
        "\n",
        "  return cross_entropy_loss_value"
      ],
      "metadata": {
        "id": "DhzBP6ZLQJ57"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_wo_hd_loss=compute_teacher_loss(image,label)"
      ],
      "metadata": {
        "id": "YIGHpYLc6r1j"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_wo_hd_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKmqlOcc6t_a",
        "outputId": "75390e5e-2e2b-424e-c3f2-c2da46a1be2d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=2.3182287>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = teacher2(image, training=True)\n",
        "teacher_wo_custom_loss= tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n"
      ],
      "metadata": {
        "id": "I9WRSE2jKXRV"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xjHCSxEM_BF",
        "outputId": "7fc36d02-9d61-4cf5-ea95-0969cb713e54"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 10), dtype=float32, numpy=\n",
              "array([[ 0.24058618, -0.02314511,  0.30385938, ..., -0.2332792 ,\n",
              "        -0.10147849,  0.1307217 ],\n",
              "       [-0.04422088,  0.05538582, -0.17397697, ..., -0.49809265,\n",
              "         0.12682721, -0.56829935],\n",
              "       [-0.14459956,  0.41171893,  0.41102475, ..., -0.1932394 ,\n",
              "         0.26690656, -0.7586017 ],\n",
              "       ...,\n",
              "       [ 0.06273146,  0.23809944, -0.376049  , ...,  0.11746404,\n",
              "        -0.07157011,  0.12225404],\n",
              "       [-0.46533528,  0.09083842,  0.18646312, ...,  0.2562029 ,\n",
              "         0.21511464,  0.11581285],\n",
              "       [ 0.15231304,  0.10416856,  0.18204793, ..., -0.21262677,\n",
              "        -0.01598365,  0.18076544]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk0cTQXMPf_4",
        "outputId": "213919c0-11bb-4b96-a43b-ecf07f3f4ea5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 10), dtype=float32, numpy=\n",
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_wo_custom_loss(label,logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe3YkWCrPj5W",
        "outputId": "454b60ae-0db4-4ed6-83c6-25d8afa14815"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=2.338126>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loass function and optimizer\n",
        "# loss_func = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5) # Low since we are fine-tuning\n"
      ],
      "metadata": {
        "id": "OQx9quoK1NM5"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# teacher.compile(loss=compute_teacher_loss(), optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "t4JO_RGI0920"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Student loss function"
      ],
      "metadata": {
        "id": "JS8xkuH0QbOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Hyperparameters for distillation (need to be tuned).\n",
        "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE = 4. #temperature hyperparameter\n",
        "\n",
        "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
        "                      temperature: Union[float, tf.Tensor]):\n",
        "  \"\"\"Compute distillation loss.\n",
        "\n",
        "  This function computes cross entropy between softened logits and softened\n",
        "  targets. The resulting loss is scaled by the squared temperature so that\n",
        "  the gradient magnitude remains approximately constant as the temperature is\n",
        "  changed. For reference, see Hinton et al., 2014, \"Distilling the knowledge in\n",
        "  a neural network.\"\n",
        "\n",
        "  Args:\n",
        "    teacher_logits: A Tensor of logits provided by the teacher.\n",
        "    student_logits: A Tensor of logits provided by the student, of the same\n",
        "      shape as `teacher_logits`.\n",
        "    temperature: Temperature to use for distillation.\n",
        "\n",
        "  Returns:\n",
        "    A scalar Tensor containing the distillation loss.\n",
        "  \"\"\"\n",
        " # your code start from here for step 3\n",
        "  soft_targets = teacher_logits / temperature\n",
        "\n",
        "  return tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(\n",
        "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
        "\n",
        "def compute_student_loss(images, labels):\n",
        "  \"\"\"Compute class knowledge distillation student loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  student_class_logits = student(images, training=True)\n",
        "\n",
        "  # Compute class distillation loss between student class logits and\n",
        "  # softened teacher class targets probabilities.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  teacher_class_logits = teacher(images, training=False)\n",
        "  distillation_loss_value =distillation_loss(teacher_class_logits,student_class_logits,DISTILLATION_TEMPERATURE)\n",
        "\n",
        "  # Compute cross-entropy loss with hard targets.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  cross_entropy_loss_value = tf.keras.losses.categorical_crossentropy(labels, student_class_logits, from_logits=True)\n",
        "  \n",
        "  total_loss =ALPHA*cross_entropy_loss_value + (1-ALPHA)*distillation_loss_value\n",
        "\n",
        "  return total_loss"
      ],
      "metadata": {
        "id": "lDKia4gPQMIr"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and evaluation"
      ],
      "metadata": {
        "id": "RJ1uyvurQ3w4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def compute_num_correct(model, images, labels):\n",
        "  \"\"\"Compute number of correctly classified images in a batch.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Number of correctly classified images.\n",
        "  \"\"\"\n",
        "  class_logits = model(images, training=False)\n",
        "  return tf.reduce_sum(\n",
        "      tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),\n",
        "              tf.float32)), tf.argmax(class_logits, -1), tf.argmax(labels, -1)"
      ],
      "metadata": {
        "id": "vygnSV4yRvB8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, compute_loss_fn):\n",
        "  \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # your code start from here for step 4\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "\n",
        "  for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    for images, labels in mnist_train:\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4\n",
        "        logits = model(images, training=True)\n",
        "        loss_value = compute_loss_fn(labels,logits)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = builder.info.splits['test'].num_examples\n",
        "    for images, labels in mnist_test:\n",
        "      # your code start from here for step 4\n",
        "      print(\"Training loss : %.4f\" % (float(loss_value)))\n",
        "    #   num_correct += compute_num_correct(model,images,labels)\n",
        "    # print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "    #     num_correct / num_total * 100))\n"
      ],
      "metadata": {
        "id": "EtoLbp8uQ4Vl"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate(teacher2,tf.keras.losses.CategoricalCrossentropy(from_logits=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ex0TwES_0yv",
        "outputId": "f1ba378e-afd5-4ade-ecf0-8df07887f9af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training models"
      ],
      "metadata": {
        "id": "NQL1lJdaRPT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code start from here for step 5 \n",
        "\n"
      ],
      "metadata": {
        "id": "-AGHbyABRPz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test accuracy vs. tempreture curve"
      ],
      "metadata": {
        "id": "sj1N38fnRTNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code start from here for step 6\n"
      ],
      "metadata": {
        "id": "gX4dbazrRWIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train student from scratch"
      ],
      "metadata": {
        "id": "WNrH_1emRbGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build fully connected student.\n",
        "fc_model_no_distillation = tf.keras.Sequential()\n",
        "\n",
        "# your code start from here for step 7\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def compute_plain_cross_entropy_loss(images, labels):\n",
        "  \"\"\"Compute plain loss for given images and labels.\n",
        "\n",
        "  For fair comparison and convenience, this function also performs a\n",
        "  LogSumExp over classes, but does not perform class distillation.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  # your code start from here for step 7\n",
        "\n",
        "  student_class_logits = fc_model_no_distillation(images, training=True)\n",
        "  cross_entropy_loss =  tf.keras.losses.categorical_crossentropy(labels, student_class_logits, from_logits=True)\n",
        "  \n",
        "  return cross_entropy_loss\n",
        "\n",
        "\n",
        "train_and_evaluate(fc_model_no_distillation, compute_plain_cross_entropy_loss)"
      ],
      "metadata": {
        "id": "HjospsxIRbQ6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "57b083e4-a876-41ea-8fad-237592851b76"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-5cade0805bd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc_model_no_distillation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_plain_cross_entropy_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_and_evaluate' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing the teacher and student model (number of of parameters and FLOPs) "
      ],
      "metadata": {
        "id": "yq3JTpQ4RuhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code start from here for step 8\n"
      ],
      "metadata": {
        "id": "4V8GB2yRRuxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XAI method to explain models"
      ],
      "metadata": {
        "id": "8b5yNhJfRu-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code start from here for step 9\n"
      ],
      "metadata": {
        "id": "yFgp5kA5RvID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing the state-of-the-art KD algorithm"
      ],
      "metadata": {
        "id": "KjwJ5oziRvRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code start from here for step 13\n"
      ],
      "metadata": {
        "id": "q10lybAFRvZt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}