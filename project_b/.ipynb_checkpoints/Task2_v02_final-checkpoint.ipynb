{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WYMfvCNPwpm",
    "tags": []
   },
   "source": [
    "# Project B: Knowledge Distillation for Building Lightweight Deep Learning Models in Visual Classification Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vA8ppgB2P0aJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTRAIN_BATCHES = 4\\nTEST_BATCHES = 4\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from typing import Union\n",
    "\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "# Not originally included\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_flops import get_flops\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "NUM_INIT_EPOCHS = 10\n",
    "NUM_FINE_EPOCHS = 25\n",
    "\n",
    "ENTROPY_ZERO_FILLER = 1e-15\n",
    "NUM_CLASSES = 2 #SSA or HP\n",
    "TRAIN_BATCHES = int(np.floor(2176/BATCH_SIZE))\n",
    "TEST_BATCHES = int(np.floor(976/BATCH_SIZE))\n",
    "NUM_TEST_IMAGE = 976\n",
    "\n",
    "# For quick testing purposes ONLY\n",
    "\"\"\"\n",
    "TRAIN_BATCHES = 4\n",
    "TEST_BATCHES = 4\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2EFLQROP2R7",
    "tags": []
   },
   "source": [
    "# Data Loading/Augmenting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2176 images belonging to 2 classes.\n",
      "Found 976 images belonging to 2 classes.\n",
      "Found 976 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Adapted from Project A's HMT Dataset loading code to use the ImageDataGenerator to augment the data and preload labels/image batches\n",
    "\n",
    "img_dir = 'mhist_dataset/images'\n",
    "train_dir = 'mhist_dataset/images/train'\n",
    "test_dir = 'mhist_dataset/images/test'\n",
    "anno_csv = 'mhist_dataset/annotations.csv'\n",
    "\n",
    "\n",
    "if not os.path.isdir(train_dir):\n",
    "    os.mkdir(train_dir)\n",
    "if not os.path.isdir(test_dir):\n",
    "    os.mkdir(test_dir)\n",
    "    \n",
    "if not os.path.isdir(os.path.join(train_dir, '01_HP')):\n",
    "    os.mkdir(os.path.join(train_dir, '01_HP'))\n",
    "if not os.path.isdir(os.path.join(train_dir, '02_SSA')):\n",
    "    os.mkdir(os.path.join(train_dir, '02_SSA'))\n",
    "if not os.path.isdir(os.path.join(test_dir, '01_HP')):\n",
    "    os.mkdir(os.path.join(test_dir, '01_HP'))\n",
    "if not os.path.isdir(os.path.join(test_dir, '02_SSA')):\n",
    "    os.mkdir(os.path.join(test_dir, '02_SSA'))\n",
    "    \n",
    "# load csv\n",
    "# label struct: [HP, SSA]\n",
    "# labels as a list are sorted in alphabetical order as per the csv\n",
    "\n",
    "train_labels = []\n",
    "test_labels = []\n",
    "train_img = []\n",
    "test_img = []\n",
    "\n",
    "with open(anno_csv, 'r') as csvfile:\n",
    "    first_row = True\n",
    "    for row in csv.reader(csvfile):\n",
    "        if first_row:\n",
    "            first_row = False\n",
    "            continue\n",
    "        if row[3] == 'train':\n",
    "            train_img.append(row[0])\n",
    "            if row[1] == 'HP':\n",
    "                train_labels.append([1, 0])\n",
    "            elif row[1] == 'SSA':\n",
    "                train_labels.append([0, 1])\n",
    "        elif row[3] == 'test':\n",
    "            test_img.append(row[0])\n",
    "            if row[1] == 'HP':\n",
    "                test_labels.append([1, 0])\n",
    "            elif row[1] == 'SSA':\n",
    "                test_labels.append([0, 1])\n",
    "        if row[0] in os.listdir(img_dir):\n",
    "            if row[1] == 'HP' and row[3] == 'train':\n",
    "                os.rename(os.path.join(img_dir, row[0]), os.path.join(train_dir, '01_HP', row[0]))\n",
    "            elif row[1] == 'SSA' and row[3] == 'train':\n",
    "                os.rename(os.path.join(img_dir, row[0]), os.path.join(train_dir, '02_SSA', row[0]))\n",
    "            elif row[1] == 'HP' and row[3] == 'test':\n",
    "                os.rename(os.path.join(img_dir, row[0]), os.path.join(test_dir, '01_HP', row[0]))\n",
    "            elif row[1] == 'SSA' and row[3] == 'test':\n",
    "                os.rename(os.path.join(img_dir, row[0]), os.path.join(test_dir, '02_SSA', row[0]))\n",
    "    \n",
    "# Data Augmentation using ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.,\n",
    "shear_range=0.1,\n",
    "rotation_range=15,\n",
    "horizontal_flip=True,\n",
    "vertical_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "class_mode='categorical',\n",
    "interpolation='bilinear',\n",
    "target_size=(224, 224),\n",
    "batch_size=BATCH_SIZE,\n",
    "shuffle=True) # 68 batches of 32\n",
    "\n",
    "eval_generator = test_datagen.flow_from_directory(test_dir,\n",
    "class_mode='categorical',\n",
    "interpolation='bilinear',\n",
    "target_size=(224, 224),\n",
    "batch_size=244,\n",
    "shuffle=True) # single batch half of the test images to get F1 scores over full test dataset\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "class_mode='categorical',\n",
    "interpolation='bilinear',\n",
    "target_size=(224, 224),\n",
    "batch_size=BATCH_SIZE,\n",
    "shuffle=False) # 30.5 batches of 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAZwfvW5P63q",
    "tags": []
   },
   "source": [
    "# Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zINgDkA7P7BP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,568,898\n",
      "Trainable params: 23,523,458\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 1280)             2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,226,434\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 1280)             2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,226,434\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# citing https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet_v2/ResNet50V2, https://www.kaggle.com/code/suniliitb96/tutorial-keras-transfer-learning-with-resnet50/notebook,\n",
    "# https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v2/MobileNetV2 and https://github.com/Abhi-T/MNIST-CLASSIFIER-From-Scratch/blob/main/MNIST__handwritten_digit_Model.ipynb\n",
    "teacher_model = tf.keras.Sequential()\n",
    "teacher_model.add(tf.keras.applications.resnet_v2.ResNet50V2(include_top=False, pooling='avg', classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "teacher_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(teacher_model.summary())\n",
    "\n",
    "# Build fully connected students\n",
    "student_kd_model = tf.keras.Sequential()\n",
    "student_kd_model.add(tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False, pooling='avg',classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "student_kd_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(student_kd_model.summary())\n",
    "\n",
    "student_scratch_model = tf.keras.Sequential()\n",
    "student_scratch_model.add(tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False, pooling='avg',classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "student_scratch_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(student_scratch_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JWGucyrQGav",
    "tags": []
   },
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Teacher Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DhzBP6ZLQJ57"
   },
   "outputs": [],
   "source": [
    "def compute_teacher_loss(model, images, labels, **kwargs):\n",
    "    \"\"\"Compute class knowledge distillation teacher loss for given images\n",
    "     and labels.\n",
    "\n",
    "    Args:\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "    kwargs: n/a\n",
    "\n",
    "    Returns:\n",
    "    Scalar loss Tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    class_logits = model(images, training=True)\n",
    "\n",
    "    # Compute cross-entropy loss for classes.\n",
    "    \n",
    "    cross_entropy_loss_value = tf.nn.softmax_cross_entropy_with_logits(labels, class_logits)\n",
    "\n",
    "    return cross_entropy_loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JS8xkuH0QbOS",
    "tags": []
   },
   "source": [
    "## Student (KD) Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "lDKia4gPQMIr"
   },
   "outputs": [],
   "source": [
    "# adapted from https://keras.io/examples/vision/knowledge_distillation/\n",
    "\n",
    "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
    "                      temperature: Union[float, tf.Tensor]):\n",
    "    \"\"\"Compute distillation loss.\n",
    "\n",
    "    This function computes cross entropy between softened logits and softened\n",
    "    targets. The resulting loss is scaled by the squared temperature so that\n",
    "    the gradient magnitude remains approximately constant as the temperature is\n",
    "    changed. For reference, see Hinton et al., 2014, \"Distilling the knowledge in\n",
    "    a neural network.\"\n",
    "\n",
    "    Args:\n",
    "    teacher_logits: A Tensor of logits provided by the teacher.\n",
    "    student_logits: A Tensor of logits provided by the student, of the same\n",
    "      shape as `teacher_logits`.\n",
    "    temperature: Temperature to use for distillation.\n",
    "\n",
    "    Returns:\n",
    "    A scalar Tensor containing the distillation loss.\n",
    "    \"\"\"\n",
    "    # your code start from here for step 3\n",
    "    soft_targets = teacher_logits / temperature\n",
    "\n",
    "    return tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(\n",
    "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
    "\n",
    "def compute_student_loss(student_model, images, labels, **kwargs):\n",
    "    \"\"\"Compute class knowledge distillation student loss for given images\n",
    "     and labels.\n",
    "\n",
    "    Args:\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "    kwargs:\n",
    "        teacher_model: Teacher model\n",
    "        temperature: Temperature hyperparameter\n",
    "        alpha: Alpha hyperparameter\n",
    "\n",
    "    Returns:\n",
    "    Scalar loss Tensor.\n",
    "    \"\"\"\n",
    "    \n",
    "    teacher_model = kwargs['teacher_model']\n",
    "    temperature = kwargs['temperature']\n",
    "    alpha = kwargs['alpha']\n",
    "    \n",
    "    student_class_logits = student_model(images, training=True)\n",
    "\n",
    "    # Compute class distillation loss between student class logits and\n",
    "    # softened teacher class targets probabilities.\n",
    "\n",
    "    teacher_class_logits = teacher_model(images, training=False)\n",
    "    distillation_loss_value = distillation_loss(teacher_class_logits, student_class_logits, temperature)\n",
    "\n",
    "    # Compute cross-entropy loss with hard targets.\n",
    "    \n",
    "    cross_entropy_loss_value = tf.nn.softmax_cross_entropy_with_logits(labels, student_class_logits)\n",
    "\n",
    "    total_loss = alpha * cross_entropy_loss_value + (1 - alpha) * distillation_loss_value\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Student (Scratch) Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_student_scratch_loss(model, images, labels, **kwargs):\n",
    "    \"\"\"Compute class student (scratch) loss for given images\n",
    "     and labels.\n",
    "\n",
    "    Args:\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "    kwargs:\n",
    "        temperature: Temperature hyperparameter\n",
    "\n",
    "    Returns:\n",
    "    Scalar loss Tensor.\n",
    "    \"\"\"\n",
    "    temperature = kwargs['temperature']\n",
    "    \n",
    "    class_logits = model(images, training=True)\n",
    "\n",
    "    # Compute cross-entropy loss for classes.\n",
    "    \n",
    "    cross_entropy_loss_value = tf.nn.softmax_cross_entropy_with_logits(labels, class_logits/temperature) * temperature ** 2\n",
    "\n",
    "    return cross_entropy_loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJ1uyvurQ3w4",
    "tags": []
   },
   "source": [
    "# Train and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EtoLbp8uQ4Vl"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_num_correct(model, images, labels):\n",
    "    \"\"\"Compute number of correctly classified images in a batch.\n",
    "\n",
    "    Args:\n",
    "    model: Instance of tf.keras.Model.\n",
    "    images: Tensor representing a batch of images.\n",
    "    labels: Tensor representing a batch of labels.\n",
    "\n",
    "    Returns:\n",
    "    Number of correctly classified images.\n",
    "    \"\"\"\n",
    "    class_logits = model(images, training=False)\n",
    "    return tf.reduce_sum(\n",
    "        tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),\n",
    "              tf.float32)), tf.argmax(class_logits, -1), tf.argmax(labels, -1)\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, compute_loss_fn, num_epochs, learning_rate, **kwargs):\n",
    "    \"\"\"Perform training and evaluation for a given model.\n",
    "\n",
    "    Args:\n",
    "    model: Main Instance of tf.keras.Model.\n",
    "    compute_loss_fn: A function that computes the training loss given the\n",
    "        images, and labels.\n",
    "    num_epochs: Number of epochs to train for\n",
    "    learning_rate: Optimizer learning rate\n",
    "    kwargs: Passed through to loss fn\n",
    "    \"\"\"\n",
    "\n",
    "    # your code start from here for step 4\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    train_generator.reset()\n",
    "    \n",
    "    accuracy = 0\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Run training.\n",
    "        print('Epoch {}: '.format(epoch), end='')\n",
    "\n",
    "        #for images, labels in mhist_train:\n",
    "        for batch in range(TRAIN_BATCHES):\n",
    "            \n",
    "            images, labels = train_generator.next()\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "\n",
    "                loss_value = compute_loss_fn(model, images, labels, **kwargs)\n",
    "\n",
    "            grads = tape.gradient(loss_value, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        # Run evaluation.\n",
    "        num_correct = 0\n",
    "        num_total = BATCH_SIZE*TEST_BATCHES\n",
    "        \n",
    "        test_generator.reset()\n",
    "        \n",
    "        for batch in range(TEST_BATCHES):\n",
    "            images, labels = test_generator.next()\n",
    "            num_correct += compute_num_correct(model,images,labels)[0]\n",
    "        accuracy = num_correct / num_total * 100\n",
    "        print(\"Class_accuracy: \" + '{:.2f}%'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQL1lJdaRPT1",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-AGHbyABRPz3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher Run: Initial\n",
      "Epoch 1: Class_accuracy: 69.88%\n",
      "Epoch 2: Class_accuracy: 74.80%\n",
      "Epoch 3: Class_accuracy: 70.90%\n",
      "Epoch 4: Class_accuracy: 76.54%\n",
      "Epoch 5: Class_accuracy: 75.82%\n",
      "Epoch 6: Class_accuracy: 77.15%\n",
      "Epoch 7: Class_accuracy: 76.23%\n",
      "Epoch 8: Class_accuracy: 71.52%\n",
      "Epoch 9: Class_accuracy: 76.54%\n",
      "Epoch 10: Class_accuracy: 74.59%\n",
      "\n",
      "Teacher Run: Fine\n",
      "Epoch 1: Class_accuracy: 85.76%\n",
      "Epoch 2: Class_accuracy: 84.73%\n",
      "Epoch 3: Class_accuracy: 85.25%\n",
      "Epoch 4: Class_accuracy: 85.66%\n",
      "Epoch 5: Class_accuracy: 86.27%\n",
      "Epoch 6: Class_accuracy: 85.45%\n",
      "Epoch 7: Class_accuracy: 85.14%\n",
      "Epoch 8: Class_accuracy: 85.25%\n",
      "Epoch 9: Class_accuracy: 85.55%\n",
      "Epoch 10: Class_accuracy: 85.25%\n",
      "Epoch 11: Class_accuracy: 84.84%\n",
      "Epoch 12: Class_accuracy: 86.27%\n",
      "Epoch 13: Class_accuracy: 84.63%\n",
      "Epoch 14: Class_accuracy: 86.27%\n",
      "Epoch 15: Class_accuracy: 87.40%\n",
      "Epoch 16: Class_accuracy: 86.99%\n",
      "Epoch 17: Class_accuracy: 85.14%\n",
      "Epoch 18: Class_accuracy: 84.32%\n",
      "Epoch 19: Class_accuracy: 86.37%\n",
      "Epoch 20: Class_accuracy: 86.68%\n",
      "Epoch 21: Class_accuracy: 85.25%\n",
      "Epoch 22: Class_accuracy: 85.45%\n",
      "Epoch 23: Class_accuracy: 86.37%\n",
      "Epoch 24: Class_accuracy: 85.35%\n",
      "Epoch 25: Class_accuracy: 84.73%\n",
      "\n",
      "\n",
      "Student (KD) Run: Initial\n",
      "Epoch 1: Class_accuracy: 42.73%\n",
      "Epoch 2: Class_accuracy: 36.78%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 63.22%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 36.78%\n",
      "\n",
      "Student (KD) Run: Fine\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 63.22%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "Epoch 11: Class_accuracy: 63.22%\n",
      "Epoch 12: Class_accuracy: 63.22%\n",
      "Epoch 13: Class_accuracy: 63.22%\n",
      "Epoch 14: Class_accuracy: 63.22%\n",
      "Epoch 15: Class_accuracy: 63.22%\n",
      "Epoch 16: Class_accuracy: 63.22%\n",
      "Epoch 17: Class_accuracy: 63.22%\n",
      "Epoch 18: Class_accuracy: 63.22%\n",
      "Epoch 19: Class_accuracy: 63.22%\n",
      "Epoch 20: Class_accuracy: 63.22%\n",
      "Epoch 21: Class_accuracy: 63.22%\n",
      "Epoch 22: Class_accuracy: 63.22%\n",
      "Epoch 23: Class_accuracy: 63.22%\n",
      "Epoch 24: Class_accuracy: 63.22%\n",
      "Epoch 25: Class_accuracy: 63.22%\n",
      "\n",
      "\n",
      "Student (Scratch) Run: Initial\n",
      "Epoch 1: Class_accuracy: 51.43%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 63.11%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 63.22%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "\n",
      "Student (Scratch) Run: Fine\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 63.32%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 62.60%\n",
      "Epoch 9: Class_accuracy: 63.73%\n",
      "Epoch 10: Class_accuracy: 63.32%\n",
      "Epoch 11: Class_accuracy: 63.63%\n",
      "Epoch 12: Class_accuracy: 63.22%\n",
      "Epoch 13: Class_accuracy: 64.96%\n",
      "Epoch 14: Class_accuracy: 63.83%\n",
      "Epoch 15: Class_accuracy: 64.75%\n",
      "Epoch 16: Class_accuracy: 65.27%\n",
      "Epoch 17: Class_accuracy: 63.52%\n",
      "Epoch 18: Class_accuracy: 63.32%\n",
      "Epoch 19: Class_accuracy: 64.14%\n",
      "Epoch 20: Class_accuracy: 63.42%\n",
      "Epoch 21: Class_accuracy: 63.52%\n",
      "Epoch 22: Class_accuracy: 63.63%\n",
      "Epoch 23: Class_accuracy: 64.24%\n",
      "Epoch 24: Class_accuracy: 66.39%\n",
      "Epoch 25: Class_accuracy: 63.52%\n"
     ]
    }
   ],
   "source": [
    "# your code start from here for step 5 \n",
    "\n",
    "print(\"Teacher Run: Initial\")\n",
    "train_and_evaluate(teacher_model, compute_teacher_loss, NUM_INIT_EPOCHS, 1e-4)\n",
    "print(\"\\nTeacher Run: Fine\")\n",
    "teach_acc = train_and_evaluate(teacher_model, compute_teacher_loss, NUM_FINE_EPOCHS, 1e-5)\n",
    "\n",
    "print(\"\\n\\nStudent (KD) Run: Initial\")\n",
    "train_and_evaluate(student_kd_model, compute_student_loss, NUM_INIT_EPOCHS, 1e-3, teacher_model=teacher_model, temperature=4, alpha=0.5)\n",
    "print(\"\\nStudent (KD) Run: Fine\")\n",
    "skd_acc = train_and_evaluate(student_kd_model, compute_student_loss, NUM_FINE_EPOCHS, 1e-4, teacher_model=teacher_model, temperature=4, alpha=0.5)\n",
    "\n",
    "print(\"\\n\\nStudent (Scratch) Run: Initial\")\n",
    "train_and_evaluate(student_scratch_model, compute_student_scratch_loss, NUM_INIT_EPOCHS, 1e-3, temperature=4)\n",
    "print(\"\\nStudent (Scratch) Run: Fine\")\n",
    "ss_acc = train_and_evaluate(student_scratch_model, compute_student_scratch_loss, NUM_FINE_EPOCHS, 1e-4, temperature=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sj1N38fnRTNB",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Test Accuracy vs. Temperature Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "gX4dbazrRWIz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student (KD, Temperature = 1) Run: Initial\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 36.78%\n",
      "Epoch 3: Class_accuracy: 42.32%\n",
      "Epoch 4: Class_accuracy: 45.39%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 45.80%\n",
      "Epoch 7: Class_accuracy: 63.11%\n",
      "Epoch 8: Class_accuracy: 59.12%\n",
      "Epoch 9: Class_accuracy: 47.03%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "\n",
      "Student (KD, Temperature = 1) Run: Fine\n",
      "Epoch 1: Class_accuracy: 63.11%\n",
      "Epoch 2: Class_accuracy: 59.32%\n",
      "Epoch 3: Class_accuracy: 61.99%\n",
      "Epoch 4: Class_accuracy: 63.63%\n",
      "Epoch 5: Class_accuracy: 61.07%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 62.81%\n",
      "Epoch 8: Class_accuracy: 63.11%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 64.24%\n",
      "Epoch 11: Class_accuracy: 63.01%\n",
      "Epoch 12: Class_accuracy: 62.70%\n",
      "Epoch 13: Class_accuracy: 63.42%\n",
      "Epoch 14: Class_accuracy: 63.11%\n",
      "Epoch 15: Class_accuracy: 62.19%\n",
      "Epoch 16: Class_accuracy: 63.01%\n",
      "Epoch 17: Class_accuracy: 62.70%\n",
      "Epoch 18: Class_accuracy: 62.50%\n",
      "Epoch 19: Class_accuracy: 62.70%\n",
      "Epoch 20: Class_accuracy: 63.63%\n",
      "Epoch 21: Class_accuracy: 63.32%\n",
      "Epoch 22: Class_accuracy: 63.11%\n",
      "Epoch 23: Class_accuracy: 63.11%\n",
      "Epoch 24: Class_accuracy: 63.01%\n",
      "Epoch 25: Class_accuracy: 63.22%\n",
      "\n",
      "\n",
      "Student (KD, Temperature = 2) Run: Initial\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 45.70%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 60.04%\n",
      "Epoch 9: Class_accuracy: 62.30%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "\n",
      "Student (KD, Temperature = 2) Run: Fine\n",
      "Epoch 1: Class_accuracy: 62.30%\n",
      "Epoch 2: Class_accuracy: 64.86%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 65.06%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.01%\n",
      "Epoch 8: Class_accuracy: 63.22%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "Epoch 11: Class_accuracy: 63.22%\n",
      "Epoch 12: Class_accuracy: 63.22%\n",
      "Epoch 13: Class_accuracy: 63.22%\n",
      "Epoch 14: Class_accuracy: 63.22%\n",
      "Epoch 15: Class_accuracy: 63.22%\n",
      "Epoch 16: Class_accuracy: 63.22%\n",
      "Epoch 17: Class_accuracy: 63.22%\n",
      "Epoch 18: Class_accuracy: 63.22%\n",
      "Epoch 19: Class_accuracy: 63.22%\n",
      "Epoch 20: Class_accuracy: 63.22%\n",
      "Epoch 21: Class_accuracy: 63.22%\n",
      "Epoch 22: Class_accuracy: 63.22%\n",
      "Epoch 23: Class_accuracy: 63.22%\n",
      "Epoch 24: Class_accuracy: 63.22%\n",
      "Epoch 25: Class_accuracy: 63.22%\n",
      "\n",
      "\n",
      "Student (KD, Temperature = 16) Run: Initial\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 36.78%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 63.22%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "\n",
      "Student (KD, Temperature = 16) Run: Fine\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 63.22%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "Epoch 11: Class_accuracy: 63.22%\n",
      "Epoch 12: Class_accuracy: 63.22%\n",
      "Epoch 13: Class_accuracy: 63.22%\n",
      "Epoch 14: Class_accuracy: 63.22%\n",
      "Epoch 15: Class_accuracy: 63.22%\n",
      "Epoch 16: Class_accuracy: 63.22%\n",
      "Epoch 17: Class_accuracy: 63.22%\n",
      "Epoch 18: Class_accuracy: 63.22%\n",
      "Epoch 19: Class_accuracy: 63.22%\n",
      "Epoch 20: Class_accuracy: 63.22%\n",
      "Epoch 21: Class_accuracy: 63.22%\n",
      "Epoch 22: Class_accuracy: 63.22%\n",
      "Epoch 23: Class_accuracy: 63.22%\n",
      "Epoch 24: Class_accuracy: 63.22%\n",
      "Epoch 25: Class_accuracy: 63.22%\n",
      "\n",
      "\n",
      "Student (KD, Temperature = 32) Run: Initial\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 36.78%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 63.22%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "\n",
      "Student (KD, Temperature = 32) Run: Fine\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 63.22%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "Epoch 11: Class_accuracy: 63.22%\n",
      "Epoch 12: Class_accuracy: 63.22%\n",
      "Epoch 13: Class_accuracy: 63.22%\n",
      "Epoch 14: Class_accuracy: 63.22%\n",
      "Epoch 15: Class_accuracy: 63.22%\n",
      "Epoch 16: Class_accuracy: 63.22%\n",
      "Epoch 17: Class_accuracy: 63.22%\n",
      "Epoch 18: Class_accuracy: 63.22%\n",
      "Epoch 19: Class_accuracy: 63.22%\n",
      "Epoch 20: Class_accuracy: 63.22%\n",
      "Epoch 21: Class_accuracy: 63.22%\n",
      "Epoch 22: Class_accuracy: 63.22%\n",
      "Epoch 23: Class_accuracy: 63.22%\n",
      "Epoch 24: Class_accuracy: 63.22%\n",
      "Epoch 25: Class_accuracy: 63.22%\n",
      "\n",
      "\n",
      "Student (KD, Temperature = 64) Run: Initial\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 63.22%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "\n",
      "Student (KD, Temperature = 64) Run: Fine\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 63.22%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "Epoch 11: Class_accuracy: 63.22%\n",
      "Epoch 12: Class_accuracy: 63.22%\n",
      "Epoch 13: Class_accuracy: 63.22%\n",
      "Epoch 14: Class_accuracy: 63.22%\n",
      "Epoch 15: Class_accuracy: 63.22%\n",
      "Epoch 16: Class_accuracy: 63.22%\n",
      "Epoch 17: Class_accuracy: 63.22%\n",
      "Epoch 18: Class_accuracy: 63.22%\n",
      "Epoch 19: Class_accuracy: 63.22%\n",
      "Epoch 20: Class_accuracy: 63.22%\n",
      "Epoch 21: Class_accuracy: 63.22%\n",
      "Epoch 22: Class_accuracy: 63.22%\n",
      "Epoch 23: Class_accuracy: 63.22%\n",
      "Epoch 24: Class_accuracy: 63.22%\n",
      "Epoch 25: Class_accuracy: 63.22%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Original student uses temperature 4\n",
    "student_kd_model1 = tf.keras.Sequential()\n",
    "student_kd_model1.add(tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False, pooling='avg',classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "student_kd_model1.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "\n",
    "student_kd_model2 = tf.keras.Sequential()\n",
    "student_kd_model2.add(tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False, pooling='avg',classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "student_kd_model2.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "\n",
    "student_kd_model16 = tf.keras.Sequential()\n",
    "student_kd_model16.add(tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False, pooling='avg',classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "student_kd_model16.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "\n",
    "student_kd_model32 = tf.keras.Sequential()\n",
    "student_kd_model32.add(tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False, pooling='avg',classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "student_kd_model32.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "\n",
    "student_kd_model64 = tf.keras.Sequential()\n",
    "student_kd_model64.add(tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False, pooling='avg',classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "student_kd_model64.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "\n",
    "student_dict = {1: student_kd_model1, 2: student_kd_model2, 4: student_kd_model, 16: student_kd_model16, 32: student_kd_model32, 64: student_kd_model64}\n",
    "acc_dict = {4: 63.32}\n",
    "\n",
    "for temp in [1, 2, 16, 32, 64]:\n",
    "    print(f'Student (KD, Temperature = {temp}) Run: Initial')\n",
    "    train_and_evaluate(student_dict[temp], compute_student_loss, NUM_INIT_EPOCHS, 1e-3, teacher_model=teacher_model, temperature=temp, alpha=0.5)\n",
    "    print(f'\\nStudent (KD, Temperature = {temp}) Run: Fine')\n",
    "    acc_dict[temp] = train_and_evaluate(student_dict[temp], compute_student_loss, NUM_FINE_EPOCHS, 1e-4, teacher_model=teacher_model, temperature=temp, alpha=0.5)\n",
    "    print('\\n')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# State of the Art Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,568,898\n",
      "Trainable params: 23,523,458\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 1280)             2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,226,434\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 1280)             2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,226,434\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "takd_teacher_model = tf.keras.Sequential()\n",
    "takd_teacher_model.add(tf.keras.applications.resnet_v2.ResNet101V2(include_top=False, pooling='avg',\n",
    "                                                                   classifier_activation = None, \n",
    "                                                                   input_shape = (224, 224, 3)))\n",
    "takd_teacher_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(takd_teacher_model.summary())\n",
    "\n",
    "takd_ta_model = tf.keras.Sequential()\n",
    "takd_ta_model.add(tf.keras.applications.resnet_v2.ResNet50V2(include_top=False, pooling='avg', \n",
    "                                                             classifier_activation = None, \n",
    "                                                             input_shape = (224, 224, 3)))\n",
    "takd_ta_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(takd_ta_model.summary())\n",
    "\n",
    "takd_student_takd_model = tf.keras.Sequential()\n",
    "takd_student_takd_model.add(tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False, pooling='avg',classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "takd_student_takd_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(takd_student_takd_model.summary())\n",
    "\n",
    "takd_student_teacherkd_model = tf.keras.Sequential()\n",
    "takd_student_teacherkd_model.add(tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False, pooling='avg',classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "takd_student_teacherkd_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(takd_student_teacherkd_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAKD Teacher Run: Initial\n",
      "\n",
      "TAKD Teacher Run: Fine\n",
      "\n",
      "TAKD TA Run: Initial\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 36.78%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 36.78%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "\n",
      "TAKD TA Run: Fine\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 59.94%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 63.22%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 59.43%\n",
      "Epoch 11: Class_accuracy: 63.22%\n",
      "Epoch 12: Class_accuracy: 63.22%\n",
      "Epoch 13: Class_accuracy: 63.22%\n",
      "Epoch 14: Class_accuracy: 63.22%\n",
      "Epoch 15: Class_accuracy: 63.22%\n",
      "Epoch 16: Class_accuracy: 49.69%\n",
      "Epoch 17: Class_accuracy: 63.22%\n",
      "Epoch 18: Class_accuracy: 63.22%\n",
      "Epoch 19: Class_accuracy: 63.22%\n",
      "Epoch 20: Class_accuracy: 63.22%\n",
      "Epoch 21: Class_accuracy: 62.70%\n",
      "Epoch 22: Class_accuracy: 54.71%\n",
      "Epoch 23: Class_accuracy: 63.22%\n",
      "Epoch 24: Class_accuracy: 57.99%\n",
      "Epoch 25: Class_accuracy: 63.22%\n",
      "\n",
      "\n",
      "TAKD Student (TA Distilled) Run: Initial\n",
      "Epoch 1: Class_accuracy: 52.25%\n",
      "Epoch 2: Class_accuracy: 36.78%\n",
      "Epoch 3: Class_accuracy: 36.78%\n",
      "Epoch 4: Class_accuracy: 36.78%\n",
      "Epoch 5: Class_accuracy: 36.78%\n",
      "Epoch 6: Class_accuracy: 36.78%\n",
      "Epoch 7: Class_accuracy: 36.78%\n",
      "Epoch 8: Class_accuracy: 36.78%\n",
      "Epoch 9: Class_accuracy: 36.78%\n",
      "Epoch 10: Class_accuracy: 36.78%\n",
      "\n",
      "TAKD Student (TA Distilled) Run: Fine\n",
      "Epoch 1: Class_accuracy: 36.78%\n",
      "Epoch 2: Class_accuracy: 36.78%\n",
      "Epoch 3: Class_accuracy: 36.78%\n",
      "Epoch 4: Class_accuracy: 36.78%\n",
      "Epoch 5: Class_accuracy: 36.78%\n",
      "Epoch 6: Class_accuracy: 36.78%\n",
      "Epoch 7: Class_accuracy: 36.78%\n",
      "Epoch 8: Class_accuracy: 36.78%\n",
      "Epoch 9: Class_accuracy: 36.78%\n",
      "Epoch 10: Class_accuracy: 36.78%\n",
      "Epoch 11: Class_accuracy: 36.78%\n",
      "Epoch 12: Class_accuracy: 36.78%\n",
      "Epoch 13: Class_accuracy: 36.78%\n",
      "Epoch 14: Class_accuracy: 36.78%\n",
      "Epoch 15: Class_accuracy: 36.78%\n",
      "Epoch 16: Class_accuracy: 36.78%\n",
      "Epoch 17: Class_accuracy: 36.78%\n",
      "Epoch 18: Class_accuracy: 36.78%\n",
      "Epoch 19: Class_accuracy: 36.78%\n",
      "Epoch 20: Class_accuracy: 36.78%\n",
      "Epoch 21: Class_accuracy: 36.78%\n",
      "Epoch 22: Class_accuracy: 36.78%\n",
      "Epoch 23: Class_accuracy: 36.78%\n",
      "Epoch 24: Class_accuracy: 36.78%\n",
      "Epoch 25: Class_accuracy: 36.78%\n",
      "\n",
      "\n",
      "TAKD Student (Teacher Distilled) Run: Initial\n",
      "Epoch 1: Class_accuracy: 36.78%\n",
      "Epoch 2: Class_accuracy: 36.78%\n",
      "Epoch 3: Class_accuracy: 36.78%\n",
      "Epoch 4: Class_accuracy: 59.02%\n",
      "Epoch 5: Class_accuracy: 61.99%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 63.22%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "\n",
      "TAKD Student (Teacher Distilled) Run: Fine\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 63.22%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "Epoch 11: Class_accuracy: 63.22%\n",
      "Epoch 12: Class_accuracy: 63.22%\n",
      "Epoch 13: Class_accuracy: 63.22%\n",
      "Epoch 14: Class_accuracy: 63.22%\n",
      "Epoch 15: Class_accuracy: 63.22%\n",
      "Epoch 16: Class_accuracy: 63.22%\n",
      "Epoch 17: Class_accuracy: 63.22%\n",
      "Epoch 18: Class_accuracy: 63.22%\n",
      "Epoch 19: Class_accuracy: 63.22%\n",
      "Epoch 20: Class_accuracy: 63.22%\n",
      "Epoch 21: Class_accuracy: 63.22%\n",
      "Epoch 22: Class_accuracy: 63.22%\n",
      "Epoch 23: Class_accuracy: 63.22%\n",
      "Epoch 24: Class_accuracy: 63.22%\n",
      "Epoch 25: Class_accuracy: 63.22%\n"
     ]
    }
   ],
   "source": [
    "print(\"TAKD Teacher Run: Initial\")\n",
    "train_and_evaluate(takd_teacher_model, compute_teacher_loss, NUM_INIT_EPOCHS, 1e-4)\n",
    "print(\"\\nTAKD Teacher Run: Fine\")\n",
    "takd_teach_acc = train_and_evaluate(takd_teacher_model, compute_teacher_loss, NUM_FINE_EPOCHS, 1e-5)\n",
    "\n",
    "print(\"\\nTAKD TA Run: Initial\")\n",
    "train_and_evaluate(takd_ta_model, compute_student_loss, NUM_INIT_EPOCHS, 1e-3, teacher_model=takd_teacher_model, temperature=4, alpha=0.5)\n",
    "print(\"\\nTAKD TA Run: Fine\")\n",
    "takd_ta_acc = train_and_evaluate(takd_ta_model, compute_student_loss, NUM_FINE_EPOCHS, 1e-4, teacher_model=takd_teacher_model, temperature=4, alpha=0.5)\n",
    "\n",
    "print(\"\\n\\nTAKD Student (TA Distilled) Run: Initial\")\n",
    "train_and_evaluate(takd_student_takd_model, compute_student_loss, NUM_INIT_EPOCHS, 1e-3, teacher_model=takd_ta_model, temperature=4, alpha=0.5)\n",
    "print(\"\\nTAKD Student (TA Distilled) Run: Fine\")\n",
    "takd_stakd_acc = train_and_evaluate(takd_student_takd_model, compute_student_loss, NUM_FINE_EPOCHS, 1e-4, teacher_model=takd_ta_model, temperature=4, alpha=0.5)\n",
    "\n",
    "print(\"\\n\\nTAKD Student (Teacher Distilled) Run: Initial\")\n",
    "train_and_evaluate(takd_student_teacherkd_model, compute_student_loss, NUM_INIT_EPOCHS, 1e-3, teacher_model=takd_teacher_model, temperature=4, alpha=0.5)\n",
    "print(\"\\nTAKD Student (Teacher Distilled) Run: Fine\")\n",
    "takd_steachkd_acc = train_and_evaluate(takd_student_teacherkd_model, compute_student_loss, NUM_FINE_EPOCHS, 1e-4, teacher_model=takd_teacher_model, temperature=4, alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model without Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 1280)             2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,226,434\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "student_notf_model = tf.keras.Sequential()\n",
    "student_notf_model.add(tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False, pooling='avg', weights=None, classifier_activation = None, input_shape = (224, 224, 3)))\n",
    "student_notf_model.add(tf.keras.layers.Dense(NUM_CLASSES)) \n",
    "print(student_kd_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student (no TF/KD) Run: Initial\n",
      "Epoch 1: Class_accuracy: 36.78%\n",
      "Epoch 2: Class_accuracy: 63.22%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 63.22%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 36.78%\n",
      "Epoch 8: Class_accuracy: 63.22%\n",
      "Epoch 9: Class_accuracy: 63.22%\n",
      "Epoch 10: Class_accuracy: 36.78%\n",
      "\n",
      "Student (no TF/KD) Run: Fine\n",
      "Epoch 1: Class_accuracy: 63.22%\n",
      "Epoch 2: Class_accuracy: 36.78%\n",
      "Epoch 3: Class_accuracy: 63.22%\n",
      "Epoch 4: Class_accuracy: 63.22%\n",
      "Epoch 5: Class_accuracy: 36.78%\n",
      "Epoch 6: Class_accuracy: 63.22%\n",
      "Epoch 7: Class_accuracy: 63.22%\n",
      "Epoch 8: Class_accuracy: 36.78%\n",
      "Epoch 9: Class_accuracy: 36.78%\n",
      "Epoch 10: Class_accuracy: 63.22%\n",
      "Epoch 11: Class_accuracy: 63.22%\n",
      "Epoch 12: Class_accuracy: 36.78%\n",
      "Epoch 13: Class_accuracy: 36.78%\n",
      "Epoch 14: Class_accuracy: 36.78%\n",
      "Epoch 15: Class_accuracy: 63.22%\n",
      "Epoch 16: Class_accuracy: 36.78%\n",
      "Epoch 17: Class_accuracy: 63.22%\n",
      "Epoch 18: Class_accuracy: 36.78%\n",
      "Epoch 19: Class_accuracy: 63.22%\n",
      "Epoch 20: Class_accuracy: 63.22%\n",
      "Epoch 21: Class_accuracy: 63.22%\n",
      "Epoch 22: Class_accuracy: 63.22%\n",
      "Epoch 23: Class_accuracy: 63.22%\n",
      "Epoch 24: Class_accuracy: 63.22%\n",
      "Epoch 25: Class_accuracy: 63.22%\n"
     ]
    }
   ],
   "source": [
    "print(\"Student (no TF/KD) Run: Initial\")\n",
    "train_and_evaluate(student_notf_model, compute_teacher_loss, NUM_INIT_EPOCHS, 1)\n",
    "print(\"\\nStudent (no TF/KD) Run: Fine\")\n",
    "takd_teach_acc = train_and_evaluate(student_notf_model, compute_teacher_loss, NUM_FINE_EPOCHS, 1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save/Load Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNrH_1emRbGA",
    "tags": []
   },
   "source": [
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('MHIST_TRAINED_MODEL'):\n",
    "    os.mkdir('MHIST_TRAINED_MODEL')\n",
    "teacher_model.save('MHIST_TRAINED_MODEL/teacher.h5')\n",
    "student_kd_model.save('MHIST_TRAINED_MODEL/student_kd4.h5')\n",
    "student_scratch_model.save('MHIST_TRAINED_MODEL/student_scratch.h5')\n",
    "student_kd_model1.save('MHIST_TRAINED_MODEL/student_kd1.h5')\n",
    "student_kd_model2.save('MHIST_TRAINED_MODEL/student_kd2.h5')\n",
    "student_kd_model16.save('MHIST_TRAINED_MODEL/student_kd16.h5')\n",
    "student_kd_model32.save('MHIST_TRAINED_MODEL/student_kd32.h5')\n",
    "student_kd_model64.save('MHIST_TRAINED_MODEL/student_kd64.h5')\n",
    "takd_teacher_model.save('MHIST_TRAINED_MODEL/takd_teacher.h5')\n",
    "takd_ta_model.save('MHIST_TRAINED_MODEL/takd_ta.h5')\n",
    "takd_student_takd_model.save('MHIST_TRAINED_MODEL/takd_student_takd.h5')\n",
    "takd_student_teacherkd_model.save('MHIST_TRAINED_MODEL/takd_student_teacherkd.h5')\n",
    "student_notf_model.save('MHIST_TRAINED_MODEL/student_notf.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq3JTpQ4RuhR"
   },
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Load the Models\n",
    "\n",
    "# Initial Teacher/Student Models\n",
    "teacher_model = tf.keras.models.load_model('MHIST_TRAINED_MODEL/teacher.h5')\n",
    "student_kd_model = tf.keras.models.load_model('MHIST_TRAINED_MODEL/student_kd4.h5')\n",
    "\n",
    "# Student from Scratch\n",
    "student_scratch_model = tf.keras.models.load_model('MHIST_TRAINED_MODEL/student_scratch.h5')\n",
    "\n",
    "# Student Temperature Sweep Models\n",
    "student_kd_model1 = tf.keras.models.load_model('MHIST_TRAINED_MODEL/student_kd1.h5')\n",
    "student_kd_model2 = tf.keras.models.load_model('MHIST_TRAINED_MODEL/student_kd2.h5')\n",
    "student_kd_model16 = tf.keras.models.load_model('MHIST_TRAINED_MODEL/student_kd16.h5')\n",
    "student_kd_model32 = tf.keras.models.load_model('MHIST_TRAINED_MODEL/student_kd32.h5')\n",
    "student_kd_model64 = tf.keras.models.load_model('MHIST_TRAINED_MODEL/student_kd64.h5')\n",
    "\n",
    "# TAKD Models\n",
    "takd_teacher_model = tf.keras.models.load_model('MHIST_TRAINED_MODEL/takd_teacher.h5')\n",
    "takd_ta_model = tf.keras.models.load_model('MHIST_TRAINED_MODEL/takd_ta.h5')\n",
    "takd_student_takd_model = tf.keras.models.load_model('MHIST_TRAINED_MODEL/takd_student_takd.h5')\n",
    "takd_student_teacherkd_model = tf.keras.models.load_model('MHIST_TRAINED_MODEL/takd_student_teacherkd.h5')\n",
    "\n",
    "# No TF\n",
    "student_notf_model = tf.keras.models.load_model('MHIST_TRAINED_MODEL/student_notf.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4V8GB2yRRuxF"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLOP/Parameter Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,568,898\n",
      "Trainable params: 23,523,458\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From c:\\users\\nich_\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:5214: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "FLOPS: 6.99 G\n",
      "\n",
      "\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 1280)             2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,226,434\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "None\n",
      "FLOPS: 0.613 G\n",
      "\n",
      "\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Funct  (None, 1280)             2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,226,434\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n",
      "None\n",
      "FLOPS: 0.613 G\n",
      "\n",
      "\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet101v2 (Functional)    (None, 2048)              42626560  \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,630,658\n",
      "Trainable params: 42,532,994\n",
      "Non-trainable params: 97,664\n",
      "_________________________________________________________________\n",
      "None\n",
      "FLOPS: 14.4 G\n",
      "\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 4098      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,568,898\n",
      "Trainable params: 23,523,458\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n",
      "None\n",
      "FLOPS: 6.99 G\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [teacher_model, student_kd_model, student_scratch_model, takd_teacher_model, takd_ta_model]:\n",
    "    print(model.summary());\n",
    "    flops = get_flops(model, batch_size=1)\n",
    "    print(f\"FLOPS: {flops / 10 ** 9:.03} G\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UAC Score Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher_model AUC = [0.9278386008400469, 0.9274943193555051]\n",
      "student_kd_model AUC = [0.4782414101769607, 0.5207946016663223]\n",
      "student_scratch_model AUC = [0.7522550437237485, 0.7540453074433656]\n",
      "student_kd_model1 AUC = [0.7220615575294361, 0.6962060180403498]\n",
      "student_kd_model2 AUC = [0.4647800041313779, 0.6077945328100255]\n",
      "student_kd_model16 AUC = [0.4926323762308063, 0.5073676237691936]\n",
      "student_kd_model32 AUC = [0.4135509192315637, 0.5872065000344282]\n",
      "student_kd_model64 AUC = [0.48402533911726225, 0.5166287957033671]\n",
      "takd_teacher_model AUC = [0.9132410658954762, 0.9151690422089102]\n",
      "takd_ta_model AUC = [0.3626661158162914, 0.6373338841837086]\n",
      "takd_student_takd_model AUC = [0.6028713075810783, 0.39461543758176687]\n",
      "takd_student_teacherkd_model AUC = [0.5074709082145562, 0.4926323762308063]\n",
      "student_notf_model AUC = [0.5, 0.5]\n"
     ]
    }
   ],
   "source": [
    "eval_generator.reset()\n",
    "image_batch,label_batch=eval_generator.next()\n",
    "\n",
    "model_list = [teacher_model, student_kd_model, student_scratch_model, \n",
    "              student_kd_model1, student_kd_model2, student_kd_model16,\n",
    "              student_kd_model32, student_kd_model64, \n",
    "              takd_teacher_model, takd_ta_model, takd_student_takd_model,\n",
    "              takd_student_teacherkd_model, student_notf_model]\n",
    "model_name_list = ['teacher_model', 'student_kd_model', 'student_scratch_model', \n",
    "                   'student_kd_model1', 'student_kd_model2', 'student_kd_model16',\n",
    "                   'student_kd_model32', 'student_kd_model64', \n",
    "                   'takd_teacher_model', 'takd_ta_model', 'takd_student_takd_model',\n",
    "                   'takd_student_teacherkd_model', 'student_notf_model']\n",
    "\n",
    "model_auc_dict = dict()\n",
    "\n",
    "for model_idx, model in enumerate(model_list):\n",
    "    \n",
    "    y_score = model.predict(image_batch)\n",
    "    y_pred = np.argmax(y_score, axis=1)\n",
    "    \n",
    "    roc_auc = [];\n",
    "    for class_idx in range(NUM_CLASSES):   \n",
    "        fpr, tpr, _ = metrics.roc_curve(label_batch[:, class_idx], y_score[:, class_idx])\n",
    "        roc_auc.append(metrics.auc(fpr, tpr))\n",
    "    model_auc_dict[model_name_list[model_idx]] = roc_auc\n",
    "    print(f'{model_name_list[model_idx]} AUC = {model_auc_dict[model_name_list[model_idx]]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Task1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
